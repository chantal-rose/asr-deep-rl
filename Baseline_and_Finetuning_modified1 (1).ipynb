{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "850c741319d14012907a83d84dba3284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b4bfe6db844449b4839b2806f48344f0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2cdaff27009c464abc7e69c06d8fb9a2",
              "IPY_MODEL_f125341334c748a3a18282af36b55bcb"
            ]
          }
        },
        "b4bfe6db844449b4839b2806f48344f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2cdaff27009c464abc7e69c06d8fb9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_5970dcce4db749089bd3fe60df8d7d7c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "0.001 MB of 0.012 MB uploaded (0.000 MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cffc1ff56d1433da2dcc653238bddf7"
          }
        },
        "f125341334c748a3a18282af36b55bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5bf06cd9ad1149348a1d327e09f5d0fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0.06172034243783123,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80f65c75ed6b45e7a7ae6b5f79191959"
          }
        },
        "5970dcce4db749089bd3fe60df8d7d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cffc1ff56d1433da2dcc653238bddf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bf06cd9ad1149348a1d327e09f5d0fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80f65c75ed6b45e7a7ae6b5f79191959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminary Setup"
      ],
      "metadata": {
        "id": "UR4qfYrVoO4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -q"
      ],
      "metadata": {
        "id": "mA9qZoIDcx-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "466a4625-5097-4384-a4d5-f2d83ddbf709"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.9 MB 30.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 70.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 59.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 70.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 65.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 83.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 83.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 57.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 158 kB 97.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 75.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 75.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 82.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 76.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 81.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 74.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 76.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 84.8 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "89rEV5XGySi9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key=\"d90e12ac420e91892a07ed5f8e37b39f5112f1a8\")"
      ],
      "metadata": {
        "id": "PiDduMaDIARE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38986816-6b66-4a79-e16d-fcf0ebd9b1fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcdgr\u001b[0m (\u001b[33mdl-studygroup\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein\n",
        "\n",
        "!pip install torchsummaryX"
      ],
      "metadata": {
        "id": "SS7a7xeEoaV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e07f0da-8aaf-41f6-a88c-aedb56e872f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.20.8-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.20.8\n",
            "  Downloading Levenshtein-0.20.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 34.0 MB/s \n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 50.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.20.8 python-Levenshtein-0.20.8 rapidfuzz-2.13.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchsummaryX\n",
            "  Downloading torchsummaryX-1.3.0-py3-none-any.whl (3.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchsummaryX) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from torchsummaryX) (1.12.1+cu113)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from torchsummaryX) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->torchsummaryX) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->torchsummaryX) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->torchsummaryX) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->torchsummaryX) (4.1.1)\n",
            "Installing collected packages: torchsummaryX\n",
            "Successfully installed torchsummaryX-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!pip install wget\n",
        "%cd ctcdecode\n",
        "!pip install .\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRsLWZ_9DeXr",
        "outputId": "5899316d-f989-4402-b3e7-a3d80e302224"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ctcdecode'...\n",
            "remote: Enumerating objects: 1102, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 1102 (delta 16), reused 32 (delta 14), pack-reused 1063\u001b[K\n",
            "Receiving objects: 100% (1102/1102), 782.27 KiB | 14.49 MiB/s, done.\n",
            "Resolving deltas: 100% (529/529), done.\n",
            "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n",
            "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n",
            "Cloning into '/content/ctcdecode/third_party/ThreadPool'...\n",
            "remote: Enumerating objects: 82, done.        \n",
            "remote: Total 82 (delta 0), reused 0 (delta 0), pack-reused 82        \n",
            "Cloning into '/content/ctcdecode/third_party/kenlm'...\n",
            "remote: Enumerating objects: 14102, done.        \n",
            "remote: Counting objects: 100% (415/415), done.        \n",
            "remote: Compressing objects: 100% (290/290), done.        \n",
            "remote: Total 14102 (delta 127), reused 381 (delta 111), pack-reused 13687        \n",
            "Receiving objects: 100% (14102/14102), 5.89 MiB | 18.17 MiB/s, done.\n",
            "Resolving deltas: 100% (8007/8007), done.\n",
            "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n",
            "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=60cdc8716974d4589a021dbf70270984d36eb4c90f108800b2d703931627a3c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "/content/ctcdecode\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/ctcdecode\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Building wheels for collected packages: ctcdecode\n",
            "  Building wheel for ctcdecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ctcdecode: filename=ctcdecode-1.0.3-cp38-cp38-linux_x86_64.whl size=13451340 sha256=c337fc7a1774f4db1309fcf2c469d9a5df362aec0dd0115be7ac24905e0c5d6a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uzjwgu7o/wheels/1f/4a/18/d4116614c3e7ef50f26cb105531a733728c0adf597584e5767\n",
            "Successfully built ctcdecode\n",
            "Installing collected packages: ctcdecode\n",
            "Successfully installed ctcdecode-1.0.3\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummaryX import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import torchaudio.transforms as tat\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# imports for decoding and distance calculation\n",
        "#import ctcdecode\n",
        "import Levenshtein\n",
        "#from ctcdecode import CTCBeamDecoder\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78ZTCIXoof2f",
        "outputId": "f8ac8a35-75d7-49bf-e7e9-c10666c7db40"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os.path as path \n",
        "# if not path.exists(\"/content/gdrive\"):\n",
        "#   !sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "#   !sudo apt-get update -qq 2>&1 > /dev/null\n",
        "#   !sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "#   !google-drive-ocamlfuse\n",
        "\n",
        "#   !sudo apt-get install -qq w3m\n",
        "#   !xdg-settings set default-web-browser w3m.desktop\n",
        "#   %cd /content\n",
        "#   !mkdir gdrive\n",
        "#   %cd gdrive\n",
        "#   !mkdir MyDrive\n",
        "#   %cd ..\n",
        "#   %cd ..\n",
        "#   !google-drive-ocamlfuse /content/gdrive/MyDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4Cp-716IMZRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a231df6-39fd-4f9d-bede-ed53741bdc9b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and preprocessing"
      ],
      "metadata": {
        "id": "gg3-yJ8tok34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/MyDrive/f0176.zip\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "316de4ca-4856-4cf2-a35a-65c2d0f045c4",
        "id": "_ruxWP60LCQA"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ctcdecode  drive  f0176  f0176.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CMUdict_ARPAbet = {\n",
        "    \"\" : \" \",\n",
        "    \"[SIL]\": \"-\", \"NG\": \"G\", \"F\" : \"f\", \"M\" : \"m\", \"AE\": \"@\", \n",
        "    \"R\"    : \"r\", \"UW\": \"u\", \"N\" : \"n\", \"IY\": \"i\", \"AW\": \"W\", \n",
        "    \"V\"    : \"v\", \"UH\": \"U\", \"OW\": \"o\", \"AA\": \"a\", \"ER\": \"R\", \n",
        "    \"HH\"   : \"h\", \"Z\" : \"z\", \"K\" : \"k\", \"CH\": \"C\", \"W\" : \"w\", \n",
        "    \"EY\"   : \"e\", \"ZH\": \"Z\", \"T\" : \"t\", \"EH\": \"E\", \"Y\" : \"y\", \n",
        "    \"AH\"   : \"A\", \"B\" : \"b\", \"P\" : \"p\", \"TH\": \"T\", \"DH\": \"D\", \n",
        "    \"AO\"   : \"c\", \"G\" : \"g\", \"L\" : \"l\", \"JH\": \"j\", \"OY\": \"O\", \n",
        "    \"SH\"   : \"S\", \"D\" : \"d\", \"AY\": \"Y\", \"S\" : \"s\", \"IH\": \"I\",\n",
        "    \"[SOS]\": \"[SOS]\", \"[EOS]\": \"[EOS]\"\n",
        "}\n",
        "\n",
        "CMUdict = list(CMUdict_ARPAbet.keys())\n",
        "ARPAbet = list(CMUdict_ARPAbet.values())\n",
        "\n",
        "\n",
        "PHONEMES = CMUdict\n",
        "mapping = CMUdict_ARPAbet\n",
        "LABELS = ARPAbet"
      ],
      "metadata": {
        "id": "k0v7wHRWrqH6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(PHONEMES)\n",
        "print(LABELS)"
      ],
      "metadata": {
        "id": "eN2kcxwXLLBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "294f68e3-9813-49ac-a747-7d3dfa95efd2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[SIL]', 'NG', 'F', 'M', 'AE', 'R', 'UW', 'N', 'IY', 'AW', 'V', 'UH', 'OW', 'AA', 'ER', 'HH', 'Z', 'K', 'CH', 'W', 'EY', 'ZH', 'T', 'EH', 'Y', 'AH', 'B', 'P', 'TH', 'DH', 'AO', 'G', 'L', 'JH', 'OY', 'SH', 'D', 'AY', 'S', 'IH', '[SOS]', '[EOS]']\n",
            "[' ', '-', 'G', 'f', 'm', '@', 'r', 'u', 'n', 'i', 'W', 'v', 'U', 'o', 'a', 'R', 'h', 'z', 'k', 'C', 'w', 'e', 'Z', 't', 'E', 'y', 'A', 'b', 'p', 'T', 'D', 'c', 'g', 'l', 'j', 'O', 'S', 'd', 'Y', 's', 'I', '[SOS]', '[EOS]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phoneme_index_mapping = dict()\n",
        "for i, phoneme in enumerate(PHONEMES):\n",
        "  phoneme_index_mapping[phoneme] = i\n",
        "print(phoneme_index_mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lde8cRM3FWhy",
        "outputId": "95f25f0b-a801-4aa1-f202-7d14e55ccc98"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': 0, '[SIL]': 1, 'NG': 2, 'F': 3, 'M': 4, 'AE': 5, 'R': 6, 'UW': 7, 'N': 8, 'IY': 9, 'AW': 10, 'V': 11, 'UH': 12, 'OW': 13, 'AA': 14, 'ER': 15, 'HH': 16, 'Z': 17, 'K': 18, 'CH': 19, 'W': 20, 'EY': 21, 'ZH': 22, 'T': 23, 'EH': 24, 'Y': 25, 'AH': 26, 'B': 27, 'P': 28, 'TH': 29, 'DH': 30, 'AO': 31, 'G': 32, 'L': 33, 'JH': 34, 'OY': 35, 'SH': 36, 'D': 37, 'AY': 38, 'S': 39, 'IH': 40, '[SOS]': 41, '[EOS]': 42}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, root_dir, subset=\"train\"): \n",
        "        '''\n",
        "        Initializes the dataset.\n",
        "        '''\n",
        "        self.root_dir = root_dir\n",
        "        self.subset = subset\n",
        "        mfcc_dir = f\"{root_dir}/{subset}.npy\"\n",
        "        trans_dir = f\"{root_dir}/{subset}_labels.npy\"\n",
        "\n",
        "        self.mfccs = torch.from_numpy(np.load(mfcc_dir))\n",
        "        self.transcripts = torch.from_numpy(np.load(trans_dir))\n",
        "\n",
        "        self.size = len(self.mfccs)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.mfccs[index], self.transcripts[index]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        mfccs = [u[0] for u in batch]\n",
        "        transcripts = [u[1] for u in batch]\n",
        "\n",
        "        mfccLens = torch.tensor([len(m) for m in mfccs])\n",
        "        transcriptLens = torch.tensor([len(t) for t in transcripts])\n",
        "\n",
        "        mfccs = pad_sequence(\n",
        "          mfccs, batch_first=True\n",
        "        )\n",
        "        transcripts = pad_sequence(\n",
        "          transcripts, batch_first=True\n",
        "        )\n",
        "        return mfccs, transcripts, mfccLens, transcriptLens\n",
        "       "
      ],
      "metadata": {
        "id": "afd0_vlbJmr_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "root = 'f0176/half2' "
      ],
      "metadata": {
        "id": "4icymeX1ImUN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc \n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_kG0gU2x4hH",
        "outputId": "3ff02f57-840f-4586-e2ad-ca454c27814a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = AudioDataset(root, subset=\"train\")\n",
        "val_data = AudioDataset(root, subset=\"dev\")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, num_workers = 4,\n",
        "                                           batch_size = BATCH_SIZE, pin_memory = True,\n",
        "                                           shuffle = True, collate_fn = train_data.collate_fn)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_data, num_workers = 2,\n",
        "                                         batch_size = BATCH_SIZE, pin_memory = True,\n",
        "                                         shuffle = False, collate_fn = val_data.collate_fn)\n",
        "\n",
        "print(\"Batch size: \", BATCH_SIZE)\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))"
      ],
      "metadata": {
        "id": "4mzoYfTKu14s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c9d17e6-849e-48e0-e6d4-0049bef95371"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  64\n",
            "Train dataset samples = 8000, batches = 125\n",
            "Val dataset samples = 800, batches = 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in train_loader:\n",
        "    x, y, lx, ly = data\n",
        "    print(x.shape, y.shape, lx.shape, ly.shape)\n",
        "    print(y[0])\n",
        "    break "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXMtwyviKaxK",
        "outputId": "cc2e4da0-b5f1-414c-e35f-15471e38120b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 176, 26]) torch.Size([64, 23]) torch.Size([64]) torch.Size([64])\n",
            "tensor([41,  1, 38,  4, 32, 24, 23, 40,  2, 39, 26,  4, 20, 26, 23, 40,  8, 11,\n",
            "        14, 33, 11, 37, 42])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition"
      ],
      "metadata": {
        "id": "Ly4mjUUUuJhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_SIZE = len(LABELS)\n",
        "OUT_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ-qQ_Sf-LIu",
        "outputId": "bc956310-08c1-49d9-cb9f-1fcaad05d3a6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMLayers(nn.Module):\n",
        "    \"\"\"\n",
        "        (Bidirectional) LSTM Module\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            dim_in: int=512,\n",
        "            hidden_dims: list=[256, 256],\n",
        "            num_layers: list=[4, 4],\n",
        "            bidirectionals: list=[True, True],\n",
        "            dropouts: list=[0.3, 0.3]\n",
        "        ):\n",
        "        \"\"\"\n",
        "            Note: locked dropout only applied once to concat layers at the end\n",
        "                    to apply one locked dropout per lstm, use LockedGroupedLSTM instead\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.dims = [dim_in] + hidden_dims\n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectionals = bidirectionals\n",
        "        self.dropouts = dropouts\n",
        "        assert (\n",
        "            len(self.dims) \n",
        "            == len(self.num_layers) + 1 \n",
        "            == len(self.bidirectionals) + 1\n",
        "        )\n",
        "\n",
        "        self.streamline = nn.ModuleList()\n",
        "        for l, dim in enumerate(self.dims[:-1]):\n",
        "            input_dim = (\n",
        "                dim * 2 if l > 0 and self.bidirectionals[l]\n",
        "                else dim\n",
        "            )\n",
        "            lstm = nn.LSTM(\n",
        "                input_size=input_dim,\n",
        "                hidden_size=self.dims[l + 1],\n",
        "                num_layers=self.num_layers[l],\n",
        "                bidirectional=self.bidirectionals[l],\n",
        "                dropout=self.dropouts[l],\n",
        "                batch_first=True\n",
        "            )\n",
        "            self.streamline.append(lstm)\n",
        "\n",
        "        \n",
        "    def forward(self, x, lx):\n",
        "        xx = pack_padded_sequence(\n",
        "            x, lengths=lx, batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        for layer in self.streamline:\n",
        "            xx, _ = layer(xx)\n",
        "        xx, lx = pad_packed_sequence(\n",
        "            xx, batch_first=True\n",
        "        )\n",
        "        return xx, lx"
      ],
      "metadata": {
        "id": "OxpMeHVUibVQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClsHead(nn.Module):\n",
        "    \"\"\"\n",
        "        Final Linear & Classification Module\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self, \n",
        "            dim_in: int=256,\n",
        "            dims: list=[512],\n",
        "            num_labels: int=43,\n",
        "            dropout: float=0.2\n",
        "        ):\n",
        "        super().__init__()\n",
        "        # bookkeeping\n",
        "        self.dims = [dim_in] + dims + [num_labels]\n",
        "        self.linears = nn.ModuleList()\n",
        "        # linear(s)\n",
        "        for i, dim in enumerate(self.dims[:-1]):\n",
        "            self.linears.append(\n",
        "                nn.Linear(\n",
        "                    in_features=dim,\n",
        "                    out_features=self.dims[i + 1]\n",
        "                )\n",
        "            )\n",
        "            if i < len(self.dims) - 2:\n",
        "                self.linears.append(nn.Dropout(dropout))\n",
        "                self.linears.append(nn.GELU())\n",
        "        assert len(self.linears) == 3 * len(self.dims) - 5\n",
        "        # logsoftmax\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.linears:\n",
        "            x = layer(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "cuaHLb3PilTj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Baseline(nn.Module):\n",
        "    \"\"\"\n",
        "        Partial network from BiLSTM to Classification.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim: int,\n",
        "            lstm_cfgs: dict,\n",
        "            cls_cfgs: dict\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.configs = {\n",
        "            'mfcc_dim': input_dim,\n",
        "            'lstm': lstm_cfgs,\n",
        "            'cls': cls_cfgs\n",
        "        }\n",
        "\n",
        "        # dim_in for lstm is the original MFCC dimensions\n",
        "        self.lstm = LSTMLayers(dim_in=input_dim, **lstm_cfgs)\n",
        "\n",
        "        # dim_in for cls is the final hidden dimension of LSTMs\n",
        "        cls_dim_in = lstm_cfgs['hidden_dims'][-1]\n",
        "\n",
        "        # alter the dimension based on whether bidirectional is enabled\n",
        "        cls_dim_in *= 2 if lstm_cfgs['bidirectionals'][-1] else 1\n",
        "        self.cls = ClsHead(dim_in=cls_dim_in, **cls_cfgs)\n",
        "    \n",
        "\n",
        "    def forward(self, x, lx):\n",
        "        # (bi)lstm layers\n",
        "        xx, lx = self.lstm(x, lx)\n",
        "        # cls layers\n",
        "        xx = self.cls(xx)\n",
        "        return xx, lx"
      ],
      "metadata": {
        "id": "YmxKXXP0io6d"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "MFCC_DIM = 26\n",
        "HIDDEN_DIMS = [128, 128]\n",
        "NUM_LAYERS = [2, 2]\n",
        "BIDIRECTIONALS = [True, True]\n",
        "LINEAR_DIMS = [256]\n",
        "DROPOUTS = [0.2, 0.2]\n",
        "NUM_PHONEMES = 43\n",
        "\n",
        "\n",
        "LSTM_CFGS = {\n",
        "    'hidden_dims': HIDDEN_DIMS,\n",
        "    'num_layers': NUM_LAYERS,\n",
        "    'bidirectionals': BIDIRECTIONALS,\n",
        "    'dropouts': DROPOUTS\n",
        "}\n",
        "\n",
        "CLS_CFGS = {\n",
        "    'dims': LINEAR_DIMS,\n",
        "    'num_labels': NUM_PHONEMES\n",
        "}\n",
        "\n",
        "model = Baseline(\n",
        "    input_dim=MFCC_DIM,\n",
        "    lstm_cfgs=LSTM_CFGS,\n",
        "    cls_cfgs=CLS_CFGS\n",
        ")\n",
        "model = model.to(device)\n",
        "print(f\"\\n\\nModel Summary for [LSTMLayers]:\\n{summary(model, x.to(device), lx)}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSk5J2MHiuTi",
        "outputId": "da687af4-a6fb-43e6-ba1c-f603f850dcb5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================\n",
            "                         Kernel Shape    Output Shape    Params Mult-Adds\n",
            "Layer                                                                    \n",
            "0_lstm.streamline.LSTM_0            -    [11264, 256]  555.008k  550.912k\n",
            "1_lstm.streamline.LSTM_1            -    [11264, 256]  790.528k  786.432k\n",
            "2_cls.linears.Linear_0     [256, 256]  [64, 176, 256]   65.792k   65.536k\n",
            "3_cls.linears.Dropout_1             -  [64, 176, 256]         -         -\n",
            "4_cls.linears.GELU_2                -  [64, 176, 256]         -         -\n",
            "5_cls.linears.Linear_3      [256, 43]   [64, 176, 43]   11.051k   11.008k\n",
            "6_cls.Softmax_softmax               -   [64, 176, 43]         -         -\n",
            "--------------------------------------------------------------------------\n",
            "                         Totals\n",
            "Total params          1.422379M\n",
            "Trainable params      1.422379M\n",
            "Non-trainable params        0.0\n",
            "Mult-Adds             1.413888M\n",
            "==========================================================================\n",
            "\n",
            "\n",
            "Model Summary for [LSTMLayers]:\n",
            "                         Kernel Shape    Output Shape    Params  Mult-Adds\n",
            "Layer                                                                     \n",
            "0_lstm.streamline.LSTM_0            -    [11264, 256]  555008.0   550912.0\n",
            "1_lstm.streamline.LSTM_1            -    [11264, 256]  790528.0   786432.0\n",
            "2_cls.linears.Linear_0     [256, 256]  [64, 176, 256]   65792.0    65536.0\n",
            "3_cls.linears.Dropout_1             -  [64, 176, 256]       NaN        NaN\n",
            "4_cls.linears.GELU_2                -  [64, 176, 256]       NaN        NaN\n",
            "5_cls.linears.Linear_3      [256, 43]   [64, 176, 43]   11051.0    11008.0\n",
            "6_cls.Softmax_softmax               -   [64, 176, 43]       NaN        NaN\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Model Training"
      ],
      "metadata": {
        "id": "IBwunYpyugFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss functions, Optimizer, Decoder Setup"
      ],
      "metadata": {
        "id": "AVyEMAZBOF5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_config = {\n",
        "    \"beam_width\" : 3,\n",
        "    \"lr\" : 2e-3,\n",
        "    \"epochs\" : 50,\n",
        "    \"scheduler\": \"ReduceLR\",\n",
        "    \"layers\": \"LSTM(128, 128) with dropout, Linear(256)\",\n",
        "    }"
      ],
      "metadata": {
        "id": "MN82c3KpLup8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(\n",
        "    reinit = True,\n",
        "    project = \"project\",\n",
        "    config = baseline_config\n",
        ")"
      ],
      "metadata": {
        "id": "4s52yBOvICPZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430,
          "referenced_widgets": [
            "850c741319d14012907a83d84dba3284",
            "b4bfe6db844449b4839b2806f48344f0",
            "2cdaff27009c464abc7e69c06d8fb9a2",
            "f125341334c748a3a18282af36b55bcb",
            "5970dcce4db749089bd3fe60df8d7d7c",
            "4cffc1ff56d1433da2dcc653238bddf7",
            "5bf06cd9ad1149348a1d327e09f5d0fd",
            "80f65c75ed6b45e7a7ae6b5f79191959"
          ]
        },
        "outputId": "761df114-a37e-4e73-a535-2d0d217362bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:3vyb5uzx) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "850c741319d14012907a83d84dba3284",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.012 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.061720…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>levenshtein distance</td><td>█▅▅▅▅▃▁</td></tr><tr><td>train loss</td><td>█▄▃▃▃▂▁</td></tr><tr><td>validation loss</td><td>███▇▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>levenshtein distance</td><td>18.09255</td></tr><tr><td>train loss</td><td>2.6327</td></tr><tr><td>validation loss</td><td>2.55744</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">feasible-wave-6</strong>: <a href=\"https://wandb.ai/dl-studygroup/project/runs/3vyb5uzx\" target=\"_blank\">https://wandb.ai/dl-studygroup/project/runs/3vyb5uzx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20221204_142540-3vyb5uzx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Successfully finished last run (ID:3vyb5uzx). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221204_142810-mc9c1k0n</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/dl-studygroup/project/runs/mc9c1k0n\" target=\"_blank\">playful-spaceship-7</a></strong> to <a href=\"https://wandb.ai/dl-studygroup/project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer =  torch.optim.AdamW(model.parameters(), lr=baseline_config['lr'], weight_decay=1e-5) # What goes in here?"
      ],
      "metadata": {
        "id": "J7VX5D0yR-qb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.loss import CTCLoss\n",
        "\n",
        "criterion = CTCLoss()\n",
        "\n",
        "\n",
        "decoder = CTCBeamDecoder(\n",
        "    LABELS,\n",
        "    beam_width = config[\"beam_width\"],\n",
        "    num_processes = 4,\n",
        "    log_probs_input = True\n",
        ")\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = 2, factor = 0.5, min_lr = 2e-6, mode = \"min\")\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "id": "AVnXr0EsEMRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_levenshtein(h, y, lh, ly, decoder, labels):\n",
        "\n",
        "    beam_results, beam_scores, timesteps, out_lens = decoder.decode(h, seq_lens = lh)\n",
        "\n",
        "    batch_size = out_lens.shape[0]\n",
        "    distance = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      h_sliced = beam_results[i][0][:out_lens[i][0]]\n",
        "      y_sliced = y[i][:ly[i]]\n",
        "      h_string = \"\".join([labels[n] for n in h_sliced])\n",
        "      y_string = \"\".join([labels[n] for n in y_sliced])\n",
        "      distance += Levenshtein.distance(h_string, y_string)\n",
        "\n",
        "    distance /= batch_size\n",
        "\n",
        "    return distance"
      ],
      "metadata": {
        "id": "ZY9mQpDVEHLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SANITY CHECK FOR BASELINE MODEL\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(train_loader):\n",
        "\n",
        "      mfccs, phonemes, len_mfccs, len_phonemes = data\n",
        "      mfccs, phonemes = mfccs.to(device), phonemes.to(device) \n",
        "\n",
        "      with torch.cuda.amp.autocast():\n",
        "        out, lens = model(mfccs, len_mfccs)\n",
        "\n",
        "      print(\"Output of model: \", out.shape)\n",
        "\n",
        "      loss = criterion(torch.log(out).permute(1,0,2), phonemes, lens, len_phonemes) # What goes in here?\n",
        "      print(f\"loss: {loss}\")\n",
        "\n",
        "      distance = calculate_levenshtein(torch.log(out), phonemes, lens, len_phonemes, decoder, LABELS, debug = False)\n",
        "      print(f\"lev-distance: {distance}\")\n",
        "\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kjx0MqkEQLK",
        "outputId": "ab20dd2e-7547-4fc1-b354-7e1a67e64979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output of model:  torch.Size([64, 44, 43])\n",
            "loss: 5.496857166290283\n",
            "lev-distance: 29.296875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation"
      ],
      "metadata": {
        "id": "ykJJzXgSOPI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "def evaluate(data_loader, model, epoch):\n",
        "    model.eval()\n",
        "    dist = 0\n",
        "    loss = 0\n",
        "    batch_bar = tqdm(total=len(data_loader), dynamic_ncols=True, leave=False, position=0, desc='Val') \n",
        "\n",
        "    phone_true_list = []\n",
        "    phone_pred_list = []\n",
        "\n",
        "    for i, data in enumerate(data_loader):\n",
        "\n",
        "        mfccs, phonemes, len_mfccs, len_phonemes = data\n",
        "        mfccs, phonemes = mfccs.to(device), phonemes.to(device) \n",
        "\n",
        "        with torch.inference_mode():\n",
        "          out, lens = model(mfccs, len_mfccs)\n",
        "    \n",
        "\n",
        "        loss = criterion(torch.log(out).permute(1,0,2), phonemes, lens, len_phonemes)\n",
        "\n",
        "        dist += calculate_levenshtein(torch.log(out), phonemes, lens, len_phonemes, decoder, LABELS, debug = False)\n",
        "\n",
        "        del mfccs, phonemes, out\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    dist /= len(data_loader)\n",
        "\n",
        "    return loss, dist\n"
      ],
      "metadata": {
        "id": "0nqLiAmkMMBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(train_loader, model, optimizer, criterion, scheduler, scaler):\n",
        "  \n",
        "    model.train()\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "    train_loss = 0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        mfccs, phonemes, len_mfccs, len_phonemes = data\n",
        "        mfccs, phonemes = mfccs.to(device), phonemes.to(device) \n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "          out, lens = model(mfccs, len_mfccs)\n",
        "\n",
        "        loss = criterion(torch.log(out).permute(1,0,2), phonemes, lens, len_phonemes)\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            loss = f\"{train_loss/ (i+1):.4f}\",\n",
        "            lr = f\"{optimizer.param_groups[0]['lr']}\"\n",
        "        )\n",
        "\n",
        "        train_loss += loss\n",
        "        batch_bar.update()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "    \n",
        "    batch_bar.close()\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    return train_loss"
      ],
      "metadata": {
        "id": "_vH4QStLUjH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "best_val_dist = float('inf')\n",
        "\n",
        "name = \"baseline\"\n",
        "\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "for epoch in range(baseline_config['epochs']):\n",
        "    print(\"\\nEpoch {}/{}\".format(epoch+1, baseline_config['epochs']))\n",
        "    train_loss = train_step(train_loader, model, optimizer, criterion, scheduler, scaler)\n",
        "    print(\"\\tTrain Loss: {:.4f}\".format(train_loss))\n",
        "    \n",
        "    validation_loss, levenshtein_distance = evaluate(val_loader, model, epoch)\n",
        "    print(\"\\tLevenshtein Distance: {}\".format(levenshtein_distance))\n",
        "\n",
        "    validation_losses.append(validation_loss)\n",
        "\n",
        "    scheduler.step(levenshtein_distance)\n",
        "\n",
        "    if levenshtein_distance < best_val_dist:\n",
        "      path = \"/content/drive/MyDrive/checkpoint_{}.pth\".format(name) \n",
        "      print(\"Saving model\")\n",
        "      torch.save({'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'val_dist': levenshtein_distance, \n",
        "                  'epoch': epoch}, path)\n",
        "      \n",
        "      best_val_dist = levenshtein_distance\n",
        "      wandb.save('checkpoint.pth')\n",
        "    \n",
        "    wandb.log({\"train loss\": train_loss, \"levenshtein distance\": levenshtein_distance, \"validation loss\": validation_loss})\n",
        "\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "wxyZz9Du6YzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/{}.pth\".format(\"checkpoint_baseline_final\")\n",
        "checkpoint = torch.load(path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "best_val_dist = checkpoint['val_dist']"
      ],
      "metadata": {
        "id": "BiG7lT5j1TlU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Validation Distance for Baseline Model: \", best_val_dist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmzxvegt2M1m",
        "outputId": "ebb2dbae-1ab4-4539-c761-02df14028578"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation Distance for Baseline Model:  6.688701923076923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/checkpoint_first.pth\"\n",
        "checkpoint = torch.load(path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "best_val_dist = checkpoint['val_dist']"
      ],
      "metadata": {
        "id": "XPEKQPvxIIEU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Validation Distance for Baseline Model: \", best_val_dist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZTpim0VIMl3",
        "outputId": "aab67888-e6f6-44e6-c96d-527a35e31e97"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation Distance for Baseline Model:  7.1983173076923075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RL Model Training"
      ],
      "metadata": {
        "id": "p_qqy_8OP5WL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function, optimizer setup"
      ],
      "metadata": {
        "id": "J3qEh2E9QAJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning_config = {\n",
        "    \"lr\" : 1e-4,\n",
        "    \"epochs\" : 50,\n",
        "    \"scheduler\": \"ReduceLR\",\n",
        "    \"layers\": \"LSTM(128, 128) with dropout, Linear(256)\",\n",
        "    \"num_samples\": 2\n",
        "    }"
      ],
      "metadata": {
        "id": "jHuuUYY7Q87K"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()"
      ],
      "metadata": {
        "id": "D3MrPqtO31iX"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(\n",
        "    reinit = True,\n",
        "    project = \"11785-project\",\n",
        "    config = finetuning_config\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "c6f2e892-c636-4724-8598-cfb14438c880",
        "id": "V5xNYjHjRFfX"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221206_015413-2j0728z2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/dl-studygroup/11785-project/runs/2j0728z2\" target=\"_blank\">major-wildflower-8</a></strong> to <a href=\"https://wandb.ai/dl-studygroup/11785-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultinomialDecode:\n",
        "    def __init__(self, num_samples=1):\n",
        "        self.num_samples = num_samples\n",
        "    \n",
        "    def decode(self, logits, debug=False):\n",
        "      samples = torch.multinomial(logits, self.num_samples, replacement=True)\n",
        "      if debug:\n",
        "        print(logits[0], samples[0])\n",
        "      predicted = []\n",
        "      for i in range(self.num_samples):\n",
        "        pred = \"\"\n",
        "        prev = \"\"\n",
        "        for t in range(samples.shape[0]):\n",
        "          curr = mapping[PHONEMES[samples[t, i].item()]]\n",
        "\n",
        "          if t == 0:\n",
        "              pred += curr\n",
        "              prev = curr\n",
        "          else:\n",
        "              if curr != prev and curr !=\" \":\n",
        "                  pred += curr\n",
        "                  prev = curr\n",
        "              if curr == \" \":\n",
        "                  prev = \"\"\n",
        "        predicted.append(pred)\n",
        "      samples =  torch.arange(logits.size(0)).to(device)[:, None] * logits.size(1) + samples.to(device)\n",
        "      # print(samples)\n",
        "      # print(logits)\n",
        "      # print(torch.take(logits, samples))\n",
        "      # print(torch.grad_fn)\n",
        "      return predicted, torch.take(logits, samples)"
      ],
      "metadata": {
        "id": "eoBmcXlAEnd2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RLLoss:\n",
        "    def __init__(self, decoder):\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def __call__(self, logits, target, input_lengths, target_lengths, return_dist=False):\n",
        "      return self.forward(logits, target, input_lengths, target_lengths, return_dist)\n",
        "\n",
        "    def forward(self, logits, target, input_lengths, target_lengths, return_dist=False):\n",
        "      batch_size, timesteps, _ = logits.shape\n",
        "\n",
        "      total_loss = 0.0\n",
        "\n",
        "      total_dist = 0.0\n",
        "\n",
        "      debug = False\n",
        "      for i in range(batch_size):\n",
        "        probs = logits[i, :input_lengths[i], :]\n",
        "        if i == 1:\n",
        "          debug = False\n",
        "        else:\n",
        "          debug = False\n",
        "        predicted, probs = self.decoder.decode(probs, debug)\n",
        "\n",
        "\n",
        "        actual = \"\".join([mapping[PHONEMES[j]] for j in target[i, :target_lengths[i]]])\n",
        "\n",
        "        sample_distances = []\n",
        "\n",
        "\n",
        "        for sample in range(len(predicted)):\n",
        "          sample_distances.append(Levenshtein.distance(predicted[sample], actual))\n",
        "          # print('Predicted : ', predicted[sample])\n",
        "          # print('Actual: ', actual)\n",
        "          # print()\n",
        "          #print(sample_distances[-1])\n",
        "        \n",
        "        total_dist += sum(sample_distances) / len(predicted)\n",
        "        sample_distances = torch.tensor(sample_distances, dtype=torch.float, requires_grad=True).to(device)\n",
        "        sample_distances = sample_distances - torch.mean(sample_distances)\n",
        "        total_loss += torch.sum(sample_distances * torch.sum(torch.log(probs), axis=0)) / len(predicted)\n",
        "\n",
        "      total_loss = total_loss / batch_size\n",
        "      total_dist = total_dist / batch_size\n",
        "      if return_dist:\n",
        "        return total_loss, total_dist\n",
        "\n",
        "      return total_loss"
      ],
      "metadata": {
        "id": "hpTDVKusDEy9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = MultinomialDecode(finetuning_config[\"num_samples\"])\n",
        "\n",
        "criterion = RLLoss(decoder)\n",
        "\n",
        "optimizer =  torch.optim.AdamW(model.parameters(), lr=finetuning_config['lr'], weight_decay=1e-4) # What goes in here?\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = 5, factor = 0.2, min_lr = 1e-7, mode = \"min\", verbose=True)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "id": "iGoozH2nd6KB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SANITY CHECK FOR FINE-TUNING\n",
        "model = model.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(train_loader):\n",
        "      \n",
        "      mfccs, phonemes, len_mfccs, len_phonemes = data\n",
        "      mfccs, phonemes = mfccs.to(device), phonemes.to(device) \n",
        "      print(mfccs.shape)\n",
        "      print(phonemes.shape)\n",
        "\n",
        "      with torch.cuda.amp.autocast():\n",
        "        out, lens = model(mfccs, len_mfccs)\n",
        "\n",
        "      print(\"Output of model: \", out.shape)\n",
        "\n",
        "      loss, dist = criterion(out, phonemes, lens, len_phonemes, return_dist=True)\n",
        "      print(f\"loss: {loss}\")\n",
        "      print(f\"lev dist: {dist}\")\n",
        "\n",
        "      break"
      ],
      "metadata": {
        "id": "GnTLL-5gMBrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeddf012-a146-42b8-a7fc-75b091af935f"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 176, 26])\n",
            "torch.Size([64, 23])\n",
            "Output of model:  torch.Size([64, 176, 43])\n",
            "Predicted :  [SOS]-AtlazAvstosSi@tAdInRmn[EOS]\n",
            "Actual:  [SOS]-ItwazAsosietAdInDErm[EOS]\n",
            "\n",
            "Predicted :  [SOS]-ItvwIzAvsAtSi@tAdInRm[EOS]\n",
            "Actual:  [SOS]-ItwazAsosietAdInDErm[EOS]\n",
            "\n",
            "Predicted :  [SOS]-DATmGizUr-kEptInDAos[EOS]\n",
            "Actual:  [SOS]-nATIGiziRk-k@ptAnEmo[EOS]\n",
            "\n",
            "Predicted :  [SOS]-DATAmizyIrkEptInDEmo[EOS]\n",
            "Actual:  [SOS]-nATIGiziRk-k@ptAnEmo[EOS]\n",
            "\n",
            "Predicted :  [SOS]-mIsIzr@pejpYkyApYzAkra[EOS]\n",
            "Actual:  [SOS]-mIsIzr@mpejakyApYzAp[EOS]\n",
            "\n",
            "Predicted :  [SOS]-mIs@zr@mdpedpYkyApYzAvpa[EOS]\n",
            "Actual:  [SOS]-mIsIzr@mpejakyApYzAp[EOS]\n",
            "\n",
            "Predicted :  [SOS]-DAtmYonlitritItneWzhn[EOS]\n",
            "Actual:  [SOS]-AndYonlitritItnW@zIt[EOS]\n",
            "\n",
            "Predicted :  [SOS]-D@mYAntlitritItnWAzA[EOS]\n",
            "Actual:  [SOS]-AndYonlitritItnW@zIt[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AndhitukmYhEdInhIzl[EOS]\n",
            "Actual:  [SOS]-AndhitUkmYh@ndInhIzl[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AndhitukmYhendInhIzla[EOS]\n",
            "Actual:  [SOS]-AndhitUkmYh@ndInhIzl[EOS]\n",
            "\n",
            "Predicted :  [SOS]-wwRznhhTo--ApanAnItA[EOS]\n",
            "Actual:  [SOS]-fcrsIzItsElf-Apanmih[EOS]\n",
            "\n",
            "Predicted :  [SOS]--EzIhhIsAv---ApaniI@[EOS]\n",
            "Actual:  [SOS]-fcrsIzItsElf-Apanmih[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AndbYYttYm-zewIlIko[EOS]\n",
            "Actual:  [SOS]-AndbYD@tYm-DewIlpIkA[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AndbYt@tYmzeIoltIk[EOS]\n",
            "Actual:  [SOS]-AndbYD@tYm-DewIlpIkA[EOS]\n",
            "\n",
            "Predicted :  [SOS]-wazDprisYsodDIfesAndv[EOS]\n",
            "Actual:  [SOS]-wIDprIsYsliDAfesAndb[EOS]\n",
            "\n",
            "Predicted :  [SOS]-wazbrIsYsADIfesInD[EOS]\n",
            "Actual:  [SOS]-wIDprIsYsliDAfesAndb[EOS]\n",
            "\n",
            "Predicted :  [SOS]-husYdpYDAwIndosnokIGsA[EOS]\n",
            "Actual:  [SOS]-hus@tbYDAwIndosmokIG[EOS]\n",
            "\n",
            "Predicted :  [SOS]-hus@dpYDAwIndosnmokIGsA[EOS]\n",
            "Actual:  [SOS]-hus@tbYDAwIndosmokIG[EOS]\n",
            "\n",
            "Predicted :  [SOS]-ASWRvmcrdRkInmr@dlI[EOS]\n",
            "Actual:  [SOS]-ASWRAvmcrtRkemr@tlIG[EOS]\n",
            "\n",
            "Predicted :  [SOS]-bAsSWWRvmcrdRCIgr@dlAd[EOS]\n",
            "Actual:  [SOS]-ASWRAvmcrtRkemr@tlIG[EOS]\n",
            "\n",
            "Predicted :  [SOS]-Andh@vRSikeeAndRmYse[EOS]\n",
            "Actual:  [SOS]-AndhIDRSikemAndRmYse[EOS]\n",
            "\n",
            "Predicted :  [SOS]-Andh@vRSikeWlAndtRmYsek[EOS]\n",
            "Actual:  [SOS]-AndhIDRSikemAndRmYse[EOS]\n",
            "\n",
            "Predicted :  [SOS]-dAkrleYpREsInISAskA[EOS]\n",
            "Actual:  [SOS]-AgretwYlEvRsInsmYsIs[EOS]\n",
            "\n",
            "Predicted :  [SOS]-DAkreiYpmEDAnIzt[EOS]\n",
            "Actual:  [SOS]-AgretwYlEvRsInsmYsIs[EOS]\n",
            "\n",
            "Predicted :  [SOS]-sosorunmofAnwIz[EOS]\n",
            "Actual:  [SOS]-sAmsorImotfrAmDIslIt[EOS]\n",
            "\n",
            "Predicted :  [SOS]-sommzsoghimotfInIsG[EOS]\n",
            "Actual:  [SOS]-sAmsorImotfrAmDIslIt[EOS]\n",
            "\n",
            "Predicted :  [SOS]-fcUrAtkwUdbIkliEblIsi[EOS]\n",
            "Actual:  [SOS]-fcrItkUdbiklIrlisina[EOS]\n",
            "\n",
            "Predicted :  [SOS]-fUrAtkUddbIkliItbisi[EOS]\n",
            "Actual:  [SOS]-fcrItkUdbiklIrlisina[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AndsantYvjhYspchImdma[EOS]\n",
            "Actual:  [SOS]-AndsAmtYmzSischImanD[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AndsantYvjis@ndmanDA[EOS]\n",
            "Actual:  [SOS]-AndsAmtYmzSischImanD[EOS]\n",
            "\n",
            "Predicted :  [SOS]-duusAmwArIzEmbAtli[EOS]\n",
            "Actual:  [SOS]-tuhusAmwAtrIzEmbAliC[EOS]\n",
            "\n",
            "Predicted :  [SOS]-tuukusAmmAnrizEmbInliC[EOS]\n",
            "Actual:  [SOS]-tuhusAmwAtrIzEmbAliC[EOS]\n",
            "\n",
            "Predicted :  [SOS]-YmEnDAmhIdItDYDAtan[EOS]\n",
            "Actual:  [SOS]-mYmEndIm@ndI-tDearna[EOS]\n",
            "\n",
            "Predicted :  [SOS]-mYmEnDIhEdAtAD@DAtWa[EOS]\n",
            "Actual:  [SOS]-mYmEndIm@ndI-tDearna[EOS]\n",
            "\n",
            "Predicted :  [SOS]-fcripAGAnohAssIGmsAm[EOS]\n",
            "Actual:  [SOS]-fcryudunatnohWsunsAm[EOS]\n",
            "\n",
            "Predicted :  [SOS]-fcrigAnyYnohAsIGsAm[EOS]\n",
            "Actual:  [SOS]-fcryudunatnohWsunsAm[EOS]\n",
            "\n",
            "Predicted :  [SOS]-bAth@d-IndEvIgRnIG-dR[EOS]\n",
            "Actual:  [SOS]-bAth@d-InDAbIgInIG-d[EOS]\n",
            "\n",
            "Predicted :  [SOS]-bAthEnd-IndAbIgAnIG-d[EOS]\n",
            "Actual:  [SOS]-bAth@d-InDAbIgInIG-d[EOS]\n",
            "\n",
            "Predicted :  [SOS]-himYgaodItlAvIGliwIdhIz[EOS]\n",
            "Actual:  [SOS]-himEZRdItlAvIGliwIDh[EOS]\n",
            "\n",
            "Predicted :  [SOS]-him@yAdItlAbIGliwidhIz[EOS]\n",
            "Actual:  [SOS]-himEZRdItlAvIGliwIDh[EOS]\n",
            "\n",
            "Predicted :  [SOS]-lADRigRrirEkAldzwiC[EOS]\n",
            "Actual:  [SOS]-DAlEDRigrerIGkAlzwIC[EOS]\n",
            "\n",
            "Predicted :  [SOS]-bl@DRigrRdirEkAlzwIC[EOS]\n",
            "Actual:  [SOS]-DAlEDRigrerIGkAlzwIC[EOS]\n",
            "\n",
            "Predicted :  [SOS]-EDIGkInAprekIzhaR[EOS]\n",
            "Actual:  [SOS]-AndYmgoIGtubrekhIzha[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AfIGrInAprekhIzhR[EOS]\n",
            "Actual:  [SOS]-AndYmgoIGtubrekhIzha[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AnAsIstAdbYEnhEh@dIS[EOS]\n",
            "Actual:  [SOS]-AnAsIstIdbYEniAdISAn[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AnAsIstIdbYtIniAdISA[EOS]\n",
            "Actual:  [SOS]-AnAsIstIdbYEniAdISAn[EOS]\n",
            "\n",
            "Predicted :  [SOS]-DuhEmDItsimtubidstRn-[EOS]\n",
            "Actual:  [SOS]-tuhImItsimdtubisRtAn[EOS]\n",
            "\n",
            "Predicted :  [SOS]-D@hImIdsimtubistRn-[EOS]\n",
            "Actual:  [SOS]-tuhImItsimdtubisRtAn[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AndsclwiDA@pAcrCR[EOS]\n",
            "Actual:  [SOS]-AndsconliDA@pAlcrCRd[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AndsclliDi@bAcrdCRs[EOS]\n",
            "Actual:  [SOS]-AndsconliDA@pAlcrCRd[EOS]\n",
            "\n",
            "Predicted :  [SOS]-lItliAtriCyujufRAcf[EOS]\n",
            "Actual:  [SOS]-lEtmiEntrityutuTrocf[EOS]\n",
            "\n",
            "Predicted :  [SOS]-ltmiAtriCyACuTRrf[EOS]\n",
            "Actual:  [SOS]-lEtmiEntrityutuTrocf[EOS]\n",
            "\n",
            "Predicted :  [SOS]-SizgoDArir@ndplUk@nt[EOS]\n",
            "Actual:  [SOS]-SiwazboTwIriAndpleke[EOS]\n",
            "\n",
            "Predicted :  [SOS]-SizgoTriri@npflUk@t[EOS]\n",
            "Actual:  [SOS]-SiwazboTwIriAndpleke[EOS]\n",
            "\n",
            "Predicted :  [SOS]-DErwazAtYYmYnndAvkrc[EOS]\n",
            "Actual:  [SOS]-DErwazAtYmYmYth@vtra[EOS]\n",
            "\n",
            "Predicted :  [SOS]-DErwazAtYmYmYAr[EOS]\n",
            "Actual:  [SOS]-DErwazAtYmYmYth@vtra[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AndhAvwcrktsIwazD@gidIn[EOS]\n",
            "Actual:  [SOS]-Andh@vmcrTIGztuitAnd[EOS]\n",
            "\n",
            "Predicted :  [SOS]-And@vwcrsDIazdAgidtAnw[EOS]\n",
            "Actual:  [SOS]-Andh@vmcrTIGztuitAnd[EOS]\n",
            "\n",
            "Predicted :  [SOS]-f@ndwEnkoldkavRD@mw-[EOS]\n",
            "Actual:  [SOS]-AndwEnkoldkAvRDEmwID[EOS]\n",
            "\n",
            "Predicted :  [SOS]-EtdwInGkoldkcpRD@mw[EOS]\n",
            "Actual:  [SOS]-AndwEnkoldkAvRDEmwID[EOS]\n",
            "\n",
            "Predicted :  [SOS]-kAndfAsApmeSAnpedtuvDA[EOS]\n",
            "Actual:  [SOS]-@ntIsApeSAnpentAdDAw[EOS]\n",
            "\n",
            "Predicted :  [SOS]-kAdfRsRpeSAnpetuDA[EOS]\n",
            "Actual:  [SOS]-@ntIsApeSAnpentAdDAw[EOS]\n",
            "\n",
            "Predicted :  [SOS]-h@d@twamzbrckDAkwEfA[EOS]\n",
            "Actual:  [SOS]-h@d@twAnsbrct-DAkwEs[EOS]\n",
            "\n",
            "Predicted :  [SOS]-h@d@twcnsbrapDAkwEstS[EOS]\n",
            "Actual:  [SOS]-h@d@twAnsbrct-DAkwEs[EOS]\n",
            "\n",
            "Predicted :  [SOS]-nonwAn@vRgEnsAmprDAfRst[EOS]\n",
            "Actual:  [SOS]-nowAnEvRgEtsovRDAfRs[EOS]\n",
            "\n",
            "Predicted :  [SOS]-nAonmwEnEvRgEsAmAvpDAfRs[EOS]\n",
            "Actual:  [SOS]-nowAnEvRgEtsovRDAfRs[EOS]\n",
            "\n",
            "Predicted :  [SOS]-InfRDAoldmnTrAvIGhI[EOS]\n",
            "Actual:  [SOS]-@nsRdDAoldm@nrAbIGhI[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AnzrDAolmInTrAvIGhIzY[EOS]\n",
            "Actual:  [SOS]-@nsRdDAoldm@nrAbIGhI[EOS]\n",
            "\n",
            "Predicted :  [SOS]-alarntAdIfTEkdAvIGk[EOS]\n",
            "Actual:  [SOS]-Alarmd@tDAIfEktAvInk[EOS]\n",
            "\n",
            "Predicted :  [SOS]-carndAttdIffTEkdAvIGk[EOS]\n",
            "Actual:  [SOS]-Alarmd@tDAIfEktAvInk[EOS]\n",
            "\n",
            "Predicted :  [SOS]-hubIliDAtErzpazflz[EOS]\n",
            "Actual:  [SOS]-hubIlivdD@tDARTwazfl[EOS]\n",
            "\n",
            "Predicted :  [SOS]-hubIliDAbErIzIgwazfl@t[EOS]\n",
            "Actual:  [SOS]-hubIlivdD@tDARTwazfl[EOS]\n",
            "\n",
            "Predicted :  [SOS]-kimAntADAl@SAvm@t[EOS]\n",
            "Actual:  [SOS]-kemAndRDAl@SAvmEnitA[EOS]\n",
            "\n",
            "Predicted :  [SOS]-kemAndADAl@sAvmit[EOS]\n",
            "Actual:  [SOS]-kemAndRDAl@SAvmEnitA[EOS]\n",
            "\n",
            "Predicted :  [SOS]-EvRsEpRitIdtAzElzId[EOS]\n",
            "Actual:  [SOS]-EvRsEpRetAdDEmsElvzI[EOS]\n",
            "\n",
            "Predicted :  [SOS]-EAvRsEpRitAtImbzelsI[EOS]\n",
            "Actual:  [SOS]-EvRsEpRetAdDEmsElvzI[EOS]\n",
            "\n",
            "Predicted :  [SOS]-Andwidlivh@mpriCIGpl@[EOS]\n",
            "Actual:  [SOS]-AndwilivhImpriCIGpl@[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AndwIdlivphEmpriCIGkl[EOS]\n",
            "Actual:  [SOS]-AndwilivhImpriCIGpl@[EOS]\n",
            "\n",
            "Predicted :  [SOS]-yusihAnGjnWCWRzACARmiIrDi[EOS]\n",
            "Actual:  [SOS]-yusiInm@tRzwICarmIrl[EOS]\n",
            "\n",
            "Predicted :  [SOS]-yusiAndn@CRzAICRmirD[EOS]\n",
            "Actual:  [SOS]-yusiInm@tRzwICarmIrl[EOS]\n",
            "\n",
            "Predicted :  [SOS]-ivAnIhikAdRAsYd-onmli[EOS]\n",
            "Actual:  [SOS]-ivInIfhik@nrAsYt-onl[EOS]\n",
            "\n",
            "Predicted :  [SOS]-ivnepikEnrAsYt-onlf[EOS]\n",
            "Actual:  [SOS]-ivInIfhik@nrAsYt-onl[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AtYwUnh@v@mAnnDA@d[EOS]\n",
            "Actual:  [SOS]-bAtYwonth@vhImAnOIGy[EOS]\n",
            "\n",
            "Predicted :  [SOS]-DAtYwUnh@vIDAnDAoenu[EOS]\n",
            "Actual:  [SOS]-bAtYwonth@vhImAnOIGy[EOS]\n",
            "\n",
            "Predicted :  [SOS]-ItlrnigRzbidtAstAgpr[EOS]\n",
            "Actual:  [SOS]-yEtlEtIGhRfitACDAgrW[EOS]\n",
            "\n",
            "Predicted :  [SOS]-ItlEnigRdvidAstAgr[EOS]\n",
            "Actual:  [SOS]-yEtlEtIGhRfitACDAgrW[EOS]\n",
            "\n",
            "Predicted :  [SOS]-Def@YwAnph@piwUdbu[EOS]\n",
            "Actual:  [SOS]-IfYwRAnh@piItwUdbimY[EOS]\n",
            "\n",
            "Predicted :  [SOS]-DEfYYwRAnhEpiwUdim[EOS]\n",
            "Actual:  [SOS]-IfYwRAnh@piItwUdbimY[EOS]\n",
            "\n",
            "Predicted :  [SOS]-sYndtDAEzntIltuTApat[EOS]\n",
            "Actual:  [SOS]-so@nTiA-tIltAdDApat-[EOS]\n",
            "\n",
            "Predicted :  [SOS]-sYdDAE-tIltuDApatD[EOS]\n",
            "Actual:  [SOS]-so@nTiA-tIltAdDApat-[EOS]\n",
            "\n",
            "Predicted :  [SOS]-wAtdDrwazsAmptDIgAlt@tk[EOS]\n",
            "Actual:  [SOS]-bAtDErwazsAmTIGAvD@t[EOS]\n",
            "\n",
            "Predicted :  [SOS]-wAtdDrwazsApptIgAlt@k[EOS]\n",
            "Actual:  [SOS]-bAtDErwazsAmTIGAvD@t[EOS]\n",
            "\n",
            "Predicted :  [SOS]-wikItAnRD@tlYdAdImedm[EOS]\n",
            "Actual:  [SOS]-wik@natdInYD@thimedm[EOS]\n",
            "\n",
            "Predicted :  [SOS]-wikEtGWpDAddYdId-ImedmI[EOS]\n",
            "Actual:  [SOS]-wik@natdInYD@thimedm[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AndIndmItIzdreSAnfrumtEst[EOS]\n",
            "Actual:  [SOS]-@n@dmInIstreSAnprotE[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AndIndmIhIzgreSAnfrUtEs[EOS]\n",
            "Actual:  [SOS]-@n@dmInIstreSAnprotE[EOS]\n",
            "\n",
            "Predicted :  [SOS]-son@socrvErni-IzSikAmAd[EOS]\n",
            "Actual:  [SOS]-soD@tsoRbEriIfhikAmA[EOS]\n",
            "\n",
            "Predicted :  [SOS]-sAnAscrbEryiISzikAmA[EOS]\n",
            "Actual:  [SOS]-soD@tsoRbEriIfhikAmA[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AndsoiprezdDAklctwI[EOS]\n",
            "Actual:  [SOS]-AndsohiprezdDAklcTwI[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AndsoiprezdDAklctwI[EOS]\n",
            "Actual:  [SOS]-AndsohiprezdDAklcTwI[EOS]\n",
            "\n",
            "Predicted :  [SOS]-bAtDedIklrdDewr@DAb[EOS]\n",
            "Actual:  [SOS]-D@tDedIklErdDewRr@DR[EOS]\n",
            "\n",
            "Predicted :  [SOS]-bYledIklErdDewr@DRl@[EOS]\n",
            "Actual:  [SOS]-D@tDedIklErdDewRr@DR[EOS]\n",
            "\n",
            "Predicted :  [SOS]-D@fAnISAn@DAImAkSSAn[EOS]\n",
            "Actual:  [SOS]-dEfAnISAnAvDAImoSAnz[EOS]\n",
            "\n",
            "Predicted :  [SOS]-D@fAnISAnAvfDAYmokSSAs[EOS]\n",
            "Actual:  [SOS]-dEfAnISAnAvDAImoSAnz[EOS]\n",
            "\n",
            "Predicted :  [SOS]-fwEnhrwazAmcrfEnrEd[EOS]\n",
            "Actual:  [SOS]-w-wEnhirwaz@ncrfAnrE[EOS]\n",
            "\n",
            "Predicted :  [SOS]-TwAnhIrwazAmcrfAndrE[EOS]\n",
            "Actual:  [SOS]-w-wEnhirwaz@ncrfAnrE[EOS]\n",
            "\n",
            "Predicted :  [SOS]-bAtwAnzdIGAnatbcG[EOS]\n",
            "Actual:  [SOS]-bAtwAnTIGYmnatgoIGtu[EOS]\n",
            "\n",
            "Predicted :  [SOS]-bAtwwAnzDIGAndnatva[EOS]\n",
            "Actual:  [SOS]-bAtwAnTIGYmnatgoIGtu[EOS]\n",
            "\n",
            "Predicted :  [SOS]-IkUdnatsiD@tSuwazbI[EOS]\n",
            "Actual:  [SOS]-hikUdnatsiD@tSiwazbI[EOS]\n",
            "\n",
            "Predicted :  [SOS]-IkUdn@tTsiD@dSuwazpI[EOS]\n",
            "Actual:  [SOS]-hikUdnatsiD@tSiwazbI[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AtIGmDk@flIwIvdiGA@d[EOS]\n",
            "Actual:  [SOS]-h@vIGmedAk@TlIkAdin@[EOS]\n",
            "\n",
            "Predicted :  [SOS]-@tiGmeDAk@flIpAbdiGA-E[EOS]\n",
            "Actual:  [SOS]-h@vIGmedAk@TlIkAdin@[EOS]\n",
            "\n",
            "Predicted :  [SOS]-riDIGIsEtAt---Swaz[EOS]\n",
            "Actual:  [SOS]-EvriTIGwazsEtAld-hiw[EOS]\n",
            "\n",
            "Predicted :  [SOS]-ArITEGwIsEtAt--sdwaz[EOS]\n",
            "Actual:  [SOS]-EvriTIGwazsEtAld-hiw[EOS]\n",
            "\n",
            "Predicted :  [SOS]-nATIGkUdbimwcrtUrlisa[EOS]\n",
            "Actual:  [SOS]-nATIGkUdbimcrtruliTc[EOS]\n",
            "\n",
            "Predicted :  [SOS]-nATIGkUdbicrtrlisa[EOS]\n",
            "Actual:  [SOS]-nATIGkUdbimcrtruliTc[EOS]\n",
            "\n",
            "Predicted :  [SOS]-yIurv@RisAliscfASER[EOS]\n",
            "Actual:  [SOS]-yUrvErifIlAsafIksEdh[EOS]\n",
            "\n",
            "Predicted :  [SOS]-yUrvhEris@lAsafIk-sER[EOS]\n",
            "Actual:  [SOS]-yUrvErifIlAsafIksEdh[EOS]\n",
            "\n",
            "Predicted :  [SOS]-crtiDEnmcarDAtwEGktIGtk[EOS]\n",
            "Actual:  [SOS]-crivInmcrD@ntwEntitY[EOS]\n",
            "\n",
            "Predicted :  [SOS]-crdivEnmaD@ntEGktIt[EOS]\n",
            "Actual:  [SOS]-crivInmcrD@ntwEntitY[EOS]\n",
            "\n",
            "Predicted :  [SOS]-YdonsDAAtwazdrYtfanDERAnd[EOS]\n",
            "Actual:  [SOS]-YdontseItwazrYtfaDRA[EOS]\n",
            "\n",
            "Predicted :  [SOS]-YdodsiYtwazdrYetfanDrR-n[EOS]\n",
            "Actual:  [SOS]-YdontseItwazrYtfaDRA[EOS]\n",
            "\n",
            "Predicted :  [SOS]-DApipAlInDERh@dDIs[EOS]\n",
            "Actual:  [SOS]-DApipAlAndDErh@bAtsD[EOS]\n",
            "\n",
            "Predicted :  [SOS]-D@pipAlAnDRh@Ds[EOS]\n",
            "Actual:  [SOS]-DApipAlAndDErh@bAtsD[EOS]\n",
            "\n",
            "Predicted :  [SOS]-wYkdtIdAwewIdDDAb@kwIns[EOS]\n",
            "Actual:  [SOS]-wYptItAwewIDAb@kAvIt[EOS]\n",
            "\n",
            "Predicted :  [SOS]-wYtItAwewItDAb@kwIsp[EOS]\n",
            "Actual:  [SOS]-wYptItAwewIDAb@kAvIt[EOS]\n",
            "\n",
            "Predicted :  [SOS]-Andd@tlIdtumh-@ptIndDA[EOS]\n",
            "Actual:  [SOS]-Andb@dliIndIm@ndInDA[EOS]\n",
            "\n",
            "Predicted :  [SOS]-AndDEdlimtu@pdInDAgE[EOS]\n",
            "Actual:  [SOS]-Andb@dliIndIm@ndInDA[EOS]\n",
            "\n",
            "loss: -1.2219555377960205\n",
            "lev dist: 8.6796875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation"
      ],
      "metadata": {
        "id": "6fLLj5KIMMOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "def evaluate(data_loader, model, epoch, decoder):\n",
        "    model.eval()\n",
        "    dist = 0\n",
        "    loss = 0\n",
        "    batch_bar = tqdm(total=len(data_loader), dynamic_ncols=True, leave=False, position=0, desc='Val') \n",
        "\n",
        "    phone_true_list = []\n",
        "    phone_pred_list = []\n",
        "\n",
        "    for i, data in enumerate(data_loader):\n",
        "\n",
        "        mfccs, phonemes, len_mfccs, len_phonemes = data\n",
        "        mfccs, phonemes = mfccs.to(device), phonemes.to(device) \n",
        "\n",
        "        with torch.inference_mode():\n",
        "          out, lens = model(mfccs, len_mfccs)\n",
        "    \n",
        "\n",
        "        loss, lev_dist = criterion(out, phonemes, lens, len_phonemes, True)\n",
        "\n",
        "        dist += lev_dist\n",
        "        del mfccs, phonemes, out\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    dist /= len(data_loader)\n",
        "\n",
        "    return loss, dist\n"
      ],
      "metadata": {
        "id": "JRvfQBPYcG5A"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(train_loader, model, optimizer, criterion, scheduler, scaler):\n",
        "  \n",
        "    model.train()\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "    train_loss = 0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        mfccs, phonemes, len_mfccs, len_phonemes = data\n",
        "        mfccs, phonemes = mfccs.to(device), phonemes.to(device) \n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "          out, lens = model(mfccs, len_mfccs)\n",
        "\n",
        "        loss = criterion(out, phonemes, lens, len_phonemes)\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            loss = f\"{train_loss/ (i+1):.4f}\",\n",
        "            lr = f\"{optimizer.param_groups[0]['lr']}\"\n",
        "        )\n",
        "\n",
        "        train_loss += loss\n",
        "        batch_bar.update()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "    \n",
        "    batch_bar.close()\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    return train_loss"
      ],
      "metadata": {
        "id": "Lp9vHsnfQjit"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "best_val_dist = best_val_dist\n",
        "\n",
        "name = \"finetuning_second\"\n",
        "\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "for epoch in range(finetuning_config['epochs']):\n",
        "    print(\"\\nEpoch {}/{}\".format(epoch+1, finetuning_config['epochs']))\n",
        "    train_loss = train_step(train_loader, model, optimizer, criterion, scheduler, scaler)\n",
        "    print(\"\\tTrain Loss: {:.4f}\".format(train_loss))\n",
        "    \n",
        "    validation_loss, levenshtein_distance = evaluate(val_loader, model, epoch, decoder)\n",
        "    print(\"\\tLevenshtein Distance: {}\".format(levenshtein_distance))\n",
        "\n",
        "    validation_losses.append(validation_loss)\n",
        "\n",
        "    scheduler.step(levenshtein_distance)\n",
        "\n",
        "    if levenshtein_distance < best_val_dist:\n",
        "      path = \"/content/drive/MyDrive/checkpoint_{}.pth\".format(name) \n",
        "      print(\"Saving model\")\n",
        "      torch.save({'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'val_dist': levenshtein_distance, \n",
        "                  'epoch': epoch}, path)\n",
        "      \n",
        "      best_val_dist = levenshtein_distance\n",
        "      wandb.save('checkpoint.pth')\n",
        "    \n",
        "    wandb.log({\"train loss\": train_loss, \"levenshtein distance\": levenshtein_distance, \"validation loss\": validation_loss})\n",
        "\n",
        "run.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "F5t9wXTxIhEw",
        "outputId": "0a1bacf7-d869-4ccf-f4a7-7936aabec5a4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.2970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 15.016826923076923\n",
            "\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.0894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 16.22716346153846\n",
            "\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.0620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 16.004807692307693\n",
            "\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.0569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 16.02403846153846\n",
            "\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.0479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 16.219951923076923\n",
            "\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.0415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 16.43329326923077\n",
            "Epoch 00007: reducing learning rate of group 0 to 2.0000e-05.\n",
            "\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  98%|█████████▊| 122/125 [00:58<00:01,  2.17it/s, loss=-0.0181, lr=2e-05]"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-bf239ed9843f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinetuning_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEpoch {}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinetuning_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\tTrain Loss: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-63995f71da15>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(train_loader, model, optimizer, criterion, scheduler, scaler)\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfccs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_mfccs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphonemes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_phonemes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         batch_bar.set_postfix(\n",
            "\u001b[0;32m<ipython-input-24-538b8f8a86bc>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, logits, target, input_lengths, target_lengths, return_dist)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-538b8f8a86bc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, logits, target, input_lengths, target_lengths, return_dist)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m           \u001b[0mdebug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-423f6879f4d5>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, logits, debug)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m           \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPHONEMES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "best_val_dist = best_val_dist\n",
        "\n",
        "name = \"finetuning_second\"\n",
        "\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "for epoch in range(finetuning_config['epochs']):\n",
        "    print(\"\\nEpoch {}/{}\".format(epoch+1, finetuning_config['epochs']))\n",
        "    train_loss = train_step(train_loader, model, optimizer, criterion, scheduler, scaler)\n",
        "    print(\"\\tTrain Loss: {:.4f}\".format(train_loss))\n",
        "    \n",
        "    validation_loss, levenshtein_distance = evaluate(val_loader, model, epoch, decoder)\n",
        "    print(\"\\tLevenshtein Distance: {}\".format(levenshtein_distance))\n",
        "\n",
        "    validation_losses.append(validation_loss)\n",
        "\n",
        "    scheduler.step(levenshtein_distance)\n",
        "\n",
        "    if levenshtein_distance < best_val_dist:\n",
        "      path = \"/content/drive/MyDrive/checkpoint_{}.pth\".format(name) \n",
        "      print(\"Saving model\")\n",
        "      torch.save({'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'val_dist': levenshtein_distance, \n",
        "                  'epoch': epoch}, path)\n",
        "      \n",
        "      best_val_dist = levenshtein_distance\n",
        "      wandb.save('checkpoint.pth')\n",
        "    \n",
        "    wandb.log({\"train loss\": train_loss, \"levenshtein distance\": levenshtein_distance, \"validation loss\": validation_loss})\n",
        "\n",
        "run.finish()\n"
      ],
      "metadata": {
        "id": "-4THJ6SVRQTS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "699787e0-a591-473d-f5a7-03622d091938"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -1.0754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.778846153846154\n",
            "Saving model\n",
            "\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.8039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.737980769230769\n",
            "Saving model\n",
            "\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.7610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.65625\n",
            "Saving model\n",
            "\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.6550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.666466346153846\n",
            "\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.6057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.6532451923076925\n",
            "Saving model\n",
            "\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.6484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.6436298076923075\n",
            "Saving model\n",
            "\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.5279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.500600961538462\n",
            "Saving model\n",
            "\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.5596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.546875\n",
            "\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.5199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.493389423076923\n",
            "Saving model\n",
            "\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.5433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.678485576923077\n",
            "\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.5303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.5342548076923075\n",
            "\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.5177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.5703125\n",
            "\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.4382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.460336538461538\n",
            "Saving model\n",
            "\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.5166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.4483173076923075\n",
            "Saving model\n",
            "\n",
            "Epoch 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.5045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.512019230769231\n",
            "\n",
            "Epoch 16/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.4635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.435697115384615\n",
            "Saving model\n",
            "\n",
            "Epoch 17/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.4217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.424278846153846\n",
            "Saving model\n",
            "\n",
            "Epoch 18/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.4490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.408653846153846\n",
            "Saving model\n",
            "\n",
            "Epoch 19/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.4265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.403846153846154\n",
            "Saving model\n",
            "\n",
            "Epoch 20/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.4311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.383413461538462\n",
            "Saving model\n",
            "\n",
            "Epoch 21/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.4423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.4188701923076925\n",
            "\n",
            "Epoch 22/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.4501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.3515625\n",
            "Saving model\n",
            "\n",
            "Epoch 23/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.4033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.396033653846154\n",
            "\n",
            "Epoch 24/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.289663461538462\n",
            "Saving model\n",
            "\n",
            "Epoch 25/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.425480769230769\n",
            "\n",
            "Epoch 26/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.338341346153846\n",
            "\n",
            "Epoch 27/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.4202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.3203125\n",
            "\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.265625\n",
            "Saving model\n",
            "\n",
            "Epoch 29/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.265024038461538\n",
            "Saving model\n",
            "\n",
            "Epoch 30/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.3046875\n",
            "\n",
            "Epoch 31/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.365384615384615\n",
            "\n",
            "Epoch 32/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.4006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.338341346153846\n",
            "\n",
            "Epoch 33/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.402644230769231\n",
            "\n",
            "Epoch 34/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.376802884615385\n",
            "Epoch 00034: reducing learning rate of group 0 to 2.0000e-05.\n",
            "\n",
            "Epoch 35/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.325721153846154\n",
            "\n",
            "Epoch 36/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.3016826923076925\n",
            "\n",
            "Epoch 37/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.2920673076923075\n",
            "\n",
            "Epoch 38/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.263822115384615\n",
            "Saving model\n",
            "\n",
            "Epoch 39/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.227764423076923\n",
            "Saving model\n",
            "\n",
            "Epoch 40/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.2548076923076925\n",
            "\n",
            "Epoch 41/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.242788461538462\n",
            "\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.208533653846154\n",
            "Saving model\n",
            "\n",
            "Epoch 43/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.4174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.230168269230769\n",
            "\n",
            "Epoch 44/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.2931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.2235576923076925\n",
            "\n",
            "Epoch 45/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.275240384615385\n",
            "\n",
            "Epoch 46/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.217548076923077\n",
            "\n",
            "Epoch 47/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.209134615384615\n",
            "\n",
            "Epoch 48/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.198918269230769\n",
            "Saving model\n",
            "\n",
            "Epoch 49/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.201923076923077\n",
            "\n",
            "Epoch 50/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.3714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.1983173076923075\n",
            "Saving model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>levenshtein distance</td><td>██▇▇▆▅▅▅▅▅▄▄▄▄▄▃▄▃▃▂▃▂▂▂▃▃▃▃▂▂▂▁▂▁▁▁▁▁▁▁</td></tr><tr><td>train loss</td><td>▁▃▄▅▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████▇</td></tr><tr><td>validation loss</td><td>▁▃▅▅▄▆▇▅▇▇▆▇▆▇▆▄▆▆▇▅█▆▆▇▇▇▇█▅▆▆▆▇▇▅▅▆▅▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>levenshtein distance</td><td>7.19832</td></tr><tr><td>train loss</td><td>-0.37139</td></tr><tr><td>validation loss</td><td>-0.24819</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">comfy-dragon-7</strong>: <a href=\"https://wandb.ai/dl-studygroup/11785-project/runs/btx5bpvo\" target=\"_blank\">https://wandb.ai/dl-studygroup/11785-project/runs/btx5bpvo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221206_004009-btx5bpvo/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/checkpoint_first.pth\"\n",
        "torch.save({'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_dist': levenshtein_distance, \n",
        "            'epoch': epoch}, path)"
      ],
      "metadata": {
        "id": "LVS6bITTApE2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvrcVPIUHzsp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}