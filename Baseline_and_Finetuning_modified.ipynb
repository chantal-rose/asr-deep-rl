{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR4qfYrVoO4v"
      },
      "source": [
        "# Preliminary Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA9qZoIDcx-h",
        "outputId": "0e50be42-778d-409d-e3f6-a2d7aeb6fbc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.9 MB 8.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 75.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 72.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 78.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 65.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 67.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 78.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 80.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 158 kB 78.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 43.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 83.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 70.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 81.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 86.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 80.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 83.2 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "89rEV5XGySi9"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiDduMaDIARE",
        "outputId": "998e0323-d06f-48ab-e086-93947eb1556c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "wandb.login(key=\"4a3052b3fdb600700b0a008fd9609b86462a9130\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS7a7xeEoaV9",
        "outputId": "a0a03514-2b10-4cf9-e514-203abfea59bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.20.8-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.20.8\n",
            "  Downloading Levenshtein-0.20.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 8.3 MB/s \n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 60.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.20.8 python-Levenshtein-0.20.8 rapidfuzz-2.13.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchsummaryX\n",
            "  Downloading torchsummaryX-1.3.0-py3-none-any.whl (3.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchsummaryX) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from torchsummaryX) (1.13.0+cu116)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from torchsummaryX) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->torchsummaryX) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->torchsummaryX) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->torchsummaryX) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->torchsummaryX) (4.4.0)\n",
            "Installing collected packages: torchsummaryX\n",
            "Successfully installed torchsummaryX-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install python-Levenshtein\n",
        "\n",
        "!pip install torchsummaryX"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CTC Decode Install (for Baseline)"
      ],
      "metadata": {
        "id": "m8uvhx-wo1Wi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRsLWZ_9DeXr",
        "outputId": "5899316d-f989-4402-b3e7-a3d80e302224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ctcdecode'...\n",
            "remote: Enumerating objects: 1102, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 1102 (delta 16), reused 32 (delta 14), pack-reused 1063\u001b[K\n",
            "Receiving objects: 100% (1102/1102), 782.27 KiB | 14.49 MiB/s, done.\n",
            "Resolving deltas: 100% (529/529), done.\n",
            "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n",
            "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n",
            "Cloning into '/content/ctcdecode/third_party/ThreadPool'...\n",
            "remote: Enumerating objects: 82, done.        \n",
            "remote: Total 82 (delta 0), reused 0 (delta 0), pack-reused 82        \n",
            "Cloning into '/content/ctcdecode/third_party/kenlm'...\n",
            "remote: Enumerating objects: 14102, done.        \n",
            "remote: Counting objects: 100% (415/415), done.        \n",
            "remote: Compressing objects: 100% (290/290), done.        \n",
            "remote: Total 14102 (delta 127), reused 381 (delta 111), pack-reused 13687        \n",
            "Receiving objects: 100% (14102/14102), 5.89 MiB | 18.17 MiB/s, done.\n",
            "Resolving deltas: 100% (8007/8007), done.\n",
            "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n",
            "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=60cdc8716974d4589a021dbf70270984d36eb4c90f108800b2d703931627a3c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "/content/ctcdecode\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/ctcdecode\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Building wheels for collected packages: ctcdecode\n",
            "  Building wheel for ctcdecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ctcdecode: filename=ctcdecode-1.0.3-cp38-cp38-linux_x86_64.whl size=13451340 sha256=c337fc7a1774f4db1309fcf2c469d9a5df362aec0dd0115be7ac24905e0c5d6a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uzjwgu7o/wheels/1f/4a/18/d4116614c3e7ef50f26cb105531a733728c0adf597584e5767\n",
            "Successfully built ctcdecode\n",
            "Installing collected packages: ctcdecode\n",
            "Successfully installed ctcdecode-1.0.3\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!pip install wget\n",
        "%cd ctcdecode\n",
        "!pip install .\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ],
      "metadata": {
        "id": "Jx6nROxio6RA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78ZTCIXoof2f",
        "outputId": "b4478448-ec9d-47fd-a14a-eb1af9fb5628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummaryX import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import torchaudio.transforms as tat\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# imports for decoding and distance calculation\n",
        "#import ctcdecode\n",
        "import Levenshtein\n",
        "#from ctcdecode import CTCBeamDecoder\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Drive Mount"
      ],
      "metadata": {
        "id": "FOqWt8BWo_xn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cp-716IMZRd",
        "outputId": "6a231df6-39fd-4f9d-bede-ed53741bdc9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# import os.path as path \n",
        "# if not path.exists(\"/content/gdrive\"):\n",
        "#   !sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "#   !sudo apt-get update -qq 2>&1 > /dev/null\n",
        "#   !sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "#   !google-drive-ocamlfuse\n",
        "\n",
        "#   !sudo apt-get install -qq w3m\n",
        "#   !xdg-settings set default-web-browser w3m.desktop\n",
        "#   %cd /content\n",
        "#   !mkdir gdrive\n",
        "#   %cd gdrive\n",
        "#   !mkdir MyDrive\n",
        "#   %cd ..\n",
        "#   %cd ..\n",
        "#   !google-drive-ocamlfuse /content/gdrive/MyDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg3-yJ8tok34"
      },
      "source": [
        "# Data Loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ruxWP60LCQA",
        "outputId": "31c8ed8e-9353-4f52-e1c5-09b9ec6205e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint_baseline_final.pth  f0176  f0176.zip  sample_data\n"
          ]
        }
      ],
      "source": [
        "!unzip -q /content/f0176.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k0v7wHRWrqH6"
      },
      "outputs": [],
      "source": [
        "CMUdict_ARPAbet = {\n",
        "    \"\" : \" \",\n",
        "    \"[SIL]\": \"-\", \"NG\": \"G\", \"F\" : \"f\", \"M\" : \"m\", \"AE\": \"@\", \n",
        "    \"R\"    : \"r\", \"UW\": \"u\", \"N\" : \"n\", \"IY\": \"i\", \"AW\": \"W\", \n",
        "    \"V\"    : \"v\", \"UH\": \"U\", \"OW\": \"o\", \"AA\": \"a\", \"ER\": \"R\", \n",
        "    \"HH\"   : \"h\", \"Z\" : \"z\", \"K\" : \"k\", \"CH\": \"C\", \"W\" : \"w\", \n",
        "    \"EY\"   : \"e\", \"ZH\": \"Z\", \"T\" : \"t\", \"EH\": \"E\", \"Y\" : \"y\", \n",
        "    \"AH\"   : \"A\", \"B\" : \"b\", \"P\" : \"p\", \"TH\": \"T\", \"DH\": \"D\", \n",
        "    \"AO\"   : \"c\", \"G\" : \"g\", \"L\" : \"l\", \"JH\": \"j\", \"OY\": \"O\", \n",
        "    \"SH\"   : \"S\", \"D\" : \"d\", \"AY\": \"Y\", \"S\" : \"s\", \"IH\": \"I\",\n",
        "    \"[SOS]\": \"[SOS]\", \"[EOS]\": \"[EOS]\"\n",
        "}\n",
        "\n",
        "CMUdict = list(CMUdict_ARPAbet.keys())\n",
        "ARPAbet = list(CMUdict_ARPAbet.values())\n",
        "\n",
        "\n",
        "PHONEMES = CMUdict\n",
        "mapping = CMUdict_ARPAbet\n",
        "LABELS = ARPAbet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN2kcxwXLLBb",
        "outputId": "42f9f117-e3c0-4043-b9c7-5a400bb7a117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[SIL]', 'NG', 'F', 'M', 'AE', 'R', 'UW', 'N', 'IY', 'AW', 'V', 'UH', 'OW', 'AA', 'ER', 'HH', 'Z', 'K', 'CH', 'W', 'EY', 'ZH', 'T', 'EH', 'Y', 'AH', 'B', 'P', 'TH', 'DH', 'AO', 'G', 'L', 'JH', 'OY', 'SH', 'D', 'AY', 'S', 'IH', '[SOS]', '[EOS]']\n",
            "[' ', '-', 'G', 'f', 'm', '@', 'r', 'u', 'n', 'i', 'W', 'v', 'U', 'o', 'a', 'R', 'h', 'z', 'k', 'C', 'w', 'e', 'Z', 't', 'E', 'y', 'A', 'b', 'p', 'T', 'D', 'c', 'g', 'l', 'j', 'O', 'S', 'd', 'Y', 's', 'I', '[SOS]', '[EOS]']\n"
          ]
        }
      ],
      "source": [
        "print(PHONEMES)\n",
        "print(LABELS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lde8cRM3FWhy",
        "outputId": "90436ba3-c53f-4aed-e817-185ad135b6ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': 0, '[SIL]': 1, 'NG': 2, 'F': 3, 'M': 4, 'AE': 5, 'R': 6, 'UW': 7, 'N': 8, 'IY': 9, 'AW': 10, 'V': 11, 'UH': 12, 'OW': 13, 'AA': 14, 'ER': 15, 'HH': 16, 'Z': 17, 'K': 18, 'CH': 19, 'W': 20, 'EY': 21, 'ZH': 22, 'T': 23, 'EH': 24, 'Y': 25, 'AH': 26, 'B': 27, 'P': 28, 'TH': 29, 'DH': 30, 'AO': 31, 'G': 32, 'L': 33, 'JH': 34, 'OY': 35, 'SH': 36, 'D': 37, 'AY': 38, 'S': 39, 'IH': 40, '[SOS]': 41, '[EOS]': 42}\n"
          ]
        }
      ],
      "source": [
        "phoneme_index_mapping = dict()\n",
        "for i, phoneme in enumerate(PHONEMES):\n",
        "  phoneme_index_mapping[phoneme] = i\n",
        "print(phoneme_index_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "afd0_vlbJmr_"
      },
      "outputs": [],
      "source": [
        "class AudioDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, root_dir, subset=\"train\"): \n",
        "        '''\n",
        "        Initializes the dataset.\n",
        "        '''\n",
        "        self.root_dir = root_dir\n",
        "        self.subset = subset\n",
        "        mfcc_dir = f\"{root_dir}/{subset}.npy\"\n",
        "        trans_dir = f\"{root_dir}/{subset}_labels.npy\"\n",
        "\n",
        "        self.mfccs = torch.from_numpy(np.load(mfcc_dir))\n",
        "        self.transcripts = torch.from_numpy(np.load(trans_dir))\n",
        "\n",
        "        self.size = len(self.mfccs)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.mfccs[index], self.transcripts[index]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        mfccs = [u[0] for u in batch]\n",
        "        transcripts = [u[1] for u in batch]\n",
        "\n",
        "        mfccLens = torch.tensor([len(m) for m in mfccs])\n",
        "        transcriptLens = torch.tensor([len(t) for t in transcripts])\n",
        "\n",
        "        mfccs = pad_sequence(\n",
        "          mfccs, batch_first=True\n",
        "        )\n",
        "        transcripts = pad_sequence(\n",
        "          transcripts, batch_first=True\n",
        "        )\n",
        "        return mfccs, transcripts, mfccLens, transcriptLens\n",
        "       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4icymeX1ImUN"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "root = 'f0176/half2' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_kG0gU2x4hH",
        "outputId": "99f4e9be-6252-4ac0-c534-aaac165dcb97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import gc \n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mzoYfTKu14s",
        "outputId": "8d21cb18-848d-467c-eb4d-2731652af9b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  64\n",
            "Train dataset samples = 8000, batches = 125\n",
            "Val dataset samples = 800, batches = 13\n"
          ]
        }
      ],
      "source": [
        "train_data = AudioDataset(root, subset=\"train\")\n",
        "val_data = AudioDataset(root, subset=\"dev\")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, num_workers = 4,\n",
        "                                           batch_size = BATCH_SIZE, pin_memory = True,\n",
        "                                           shuffle = True, collate_fn = train_data.collate_fn)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_data, num_workers = 2,\n",
        "                                         batch_size = BATCH_SIZE, pin_memory = True,\n",
        "                                         shuffle = False, collate_fn = val_data.collate_fn)\n",
        "\n",
        "print(\"Batch size: \", BATCH_SIZE)\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXMtwyviKaxK",
        "outputId": "18318691-9b4b-435b-eed0-43fff1140e74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 176, 26]) torch.Size([64, 23]) torch.Size([64]) torch.Size([64])\n",
            "tensor([41,  1, 26,  8, 37, 16,  9, 23, 26, 19, 23, 30, 26, 39,  9, 33, 40,  2,\n",
            "        20, 40, 30, 26, 42])\n"
          ]
        }
      ],
      "source": [
        "for data in train_loader:\n",
        "    x, y, lx, ly = data\n",
        "    print(x.shape, y.shape, lx.shape, ly.shape)\n",
        "    print(y[0])\n",
        "    break "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly4mjUUUuJhy"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ-qQ_Sf-LIu",
        "outputId": "cd8a2072-58c3-4288-bc46-6a1228680ce1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "OUT_SIZE = len(LABELS)\n",
        "OUT_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OxpMeHVUibVQ"
      },
      "outputs": [],
      "source": [
        "class LSTMLayers(nn.Module):\n",
        "    \"\"\"\n",
        "        (Bidirectional) LSTM Module\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            dim_in: int=512,\n",
        "            hidden_dims: list=[256, 256],\n",
        "            num_layers: list=[4, 4],\n",
        "            bidirectionals: list=[True, True],\n",
        "            dropouts: list=[0.3, 0.3]\n",
        "        ):\n",
        "        \"\"\"\n",
        "            Note: locked dropout only applied once to concat layers at the end\n",
        "                    to apply one locked dropout per lstm, use LockedGroupedLSTM instead\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.dims = [dim_in] + hidden_dims\n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectionals = bidirectionals\n",
        "        self.dropouts = dropouts\n",
        "        assert (\n",
        "            len(self.dims) \n",
        "            == len(self.num_layers) + 1 \n",
        "            == len(self.bidirectionals) + 1\n",
        "        )\n",
        "\n",
        "        self.streamline = nn.ModuleList()\n",
        "        for l, dim in enumerate(self.dims[:-1]):\n",
        "            input_dim = (\n",
        "                dim * 2 if l > 0 and self.bidirectionals[l]\n",
        "                else dim\n",
        "            )\n",
        "            lstm = nn.LSTM(\n",
        "                input_size=input_dim,\n",
        "                hidden_size=self.dims[l + 1],\n",
        "                num_layers=self.num_layers[l],\n",
        "                bidirectional=self.bidirectionals[l],\n",
        "                dropout=self.dropouts[l],\n",
        "                batch_first=True\n",
        "            )\n",
        "            self.streamline.append(lstm)\n",
        "\n",
        "        \n",
        "    def forward(self, x, lx):\n",
        "        xx = pack_padded_sequence(\n",
        "            x, lengths=lx, batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        for layer in self.streamline:\n",
        "            xx, _ = layer(xx)\n",
        "        xx, lx = pad_packed_sequence(\n",
        "            xx, batch_first=True\n",
        "        )\n",
        "        return xx, lx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cuaHLb3PilTj"
      },
      "outputs": [],
      "source": [
        "class ClsHead(nn.Module):\n",
        "    \"\"\"\n",
        "        Final Linear & Classification Module\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self, \n",
        "            dim_in: int=256,\n",
        "            dims: list=[512],\n",
        "            num_labels: int=43,\n",
        "            dropout: float=0.2\n",
        "        ):\n",
        "        super().__init__()\n",
        "        # bookkeeping\n",
        "        self.dims = [dim_in] + dims + [num_labels]\n",
        "        self.linears = nn.ModuleList()\n",
        "        # linear(s)\n",
        "        for i, dim in enumerate(self.dims[:-1]):\n",
        "            self.linears.append(\n",
        "                nn.Linear(\n",
        "                    in_features=dim,\n",
        "                    out_features=self.dims[i + 1]\n",
        "                )\n",
        "            )\n",
        "            if i < len(self.dims) - 2:\n",
        "                self.linears.append(nn.Dropout(dropout))\n",
        "                self.linears.append(nn.GELU())\n",
        "        assert len(self.linears) == 3 * len(self.dims) - 5\n",
        "        # logsoftmax\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.linears:\n",
        "            x = layer(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YmxKXXP0io6d"
      },
      "outputs": [],
      "source": [
        "class Baseline(nn.Module):\n",
        "    \"\"\"\n",
        "        Partial network from BiLSTM to Classification.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim: int,\n",
        "            lstm_cfgs: dict,\n",
        "            cls_cfgs: dict\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.configs = {\n",
        "            'mfcc_dim': input_dim,\n",
        "            'lstm': lstm_cfgs,\n",
        "            'cls': cls_cfgs\n",
        "        }\n",
        "\n",
        "        # dim_in for lstm is the original MFCC dimensions\n",
        "        self.lstm = LSTMLayers(dim_in=input_dim, **lstm_cfgs)\n",
        "\n",
        "        # dim_in for cls is the final hidden dimension of LSTMs\n",
        "        cls_dim_in = lstm_cfgs['hidden_dims'][-1]\n",
        "\n",
        "        # alter the dimension based on whether bidirectional is enabled\n",
        "        cls_dim_in *= 2 if lstm_cfgs['bidirectionals'][-1] else 1\n",
        "        self.cls = ClsHead(dim_in=cls_dim_in, **cls_cfgs)\n",
        "    \n",
        "\n",
        "    def forward(self, x, lx):\n",
        "        # (bi)lstm layers\n",
        "        xx, lx = self.lstm(x, lx)\n",
        "        # cls layers\n",
        "        xx = self.cls(xx)\n",
        "        return xx, lx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSk5J2MHiuTi",
        "outputId": "ea2d2c38-8032-41d3-9eb5-cccd89e8e11e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================\n",
            "                         Kernel Shape    Output Shape    Params Mult-Adds\n",
            "Layer                                                                    \n",
            "0_lstm.streamline.LSTM_0            -    [11264, 256]  555.008k  550.912k\n",
            "1_lstm.streamline.LSTM_1            -    [11264, 256]  790.528k  786.432k\n",
            "2_cls.linears.Linear_0     [256, 256]  [64, 176, 256]   65.792k   65.536k\n",
            "3_cls.linears.Dropout_1             -  [64, 176, 256]         -         -\n",
            "4_cls.linears.GELU_2                -  [64, 176, 256]         -         -\n",
            "5_cls.linears.Linear_3      [256, 43]   [64, 176, 43]   11.051k   11.008k\n",
            "6_cls.Softmax_softmax               -   [64, 176, 43]         -         -\n",
            "--------------------------------------------------------------------------\n",
            "                         Totals\n",
            "Total params          1.422379M\n",
            "Trainable params      1.422379M\n",
            "Non-trainable params        0.0\n",
            "Mult-Adds             1.413888M\n",
            "==========================================================================\n",
            "\n",
            "\n",
            "Model Summary for [LSTMLayers]:\n",
            "                         Kernel Shape    Output Shape    Params  Mult-Adds\n",
            "Layer                                                                     \n",
            "0_lstm.streamline.LSTM_0            -    [11264, 256]  555008.0   550912.0\n",
            "1_lstm.streamline.LSTM_1            -    [11264, 256]  790528.0   786432.0\n",
            "2_cls.linears.Linear_0     [256, 256]  [64, 176, 256]   65792.0    65536.0\n",
            "3_cls.linears.Dropout_1             -  [64, 176, 256]       NaN        NaN\n",
            "4_cls.linears.GELU_2                -  [64, 176, 256]       NaN        NaN\n",
            "5_cls.linears.Linear_3      [256, 43]   [64, 176, 43]   11051.0    11008.0\n",
            "6_cls.Softmax_softmax               -   [64, 176, 43]       NaN        NaN\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "MFCC_DIM = 26\n",
        "HIDDEN_DIMS = [128, 128]\n",
        "NUM_LAYERS = [2, 2]\n",
        "BIDIRECTIONALS = [True, True]\n",
        "LINEAR_DIMS = [256]\n",
        "DROPOUTS = [0.2, 0.2]\n",
        "NUM_PHONEMES = 43\n",
        "\n",
        "\n",
        "LSTM_CFGS = {\n",
        "    'hidden_dims': HIDDEN_DIMS,\n",
        "    'num_layers': NUM_LAYERS,\n",
        "    'bidirectionals': BIDIRECTIONALS,\n",
        "    'dropouts': DROPOUTS\n",
        "}\n",
        "\n",
        "CLS_CFGS = {\n",
        "    'dims': LINEAR_DIMS,\n",
        "    'num_labels': NUM_PHONEMES\n",
        "}\n",
        "\n",
        "model = Baseline(\n",
        "    input_dim=MFCC_DIM,\n",
        "    lstm_cfgs=LSTM_CFGS,\n",
        "    cls_cfgs=CLS_CFGS\n",
        ")\n",
        "model = model.to(device)\n",
        "print(f\"\\n\\nModel Summary for [LSTMLayers]:\\n{summary(model, x.to(device), lx)}\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBwunYpyugFg"
      },
      "source": [
        "# Baseline Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVyEMAZBOF5i"
      },
      "source": [
        "## Loss functions, Optimizer, Decoder Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN82c3KpLup8"
      },
      "outputs": [],
      "source": [
        "baseline_config = {\n",
        "    \"beam_width\" : 3,\n",
        "    \"lr\" : 2e-3,\n",
        "    \"epochs\" : 50,\n",
        "    \"scheduler\": \"ReduceLR\",\n",
        "    \"layers\": \"LSTM(128, 128) with dropout, Linear(256)\",\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "4s52yBOvICPZ",
        "outputId": "761df114-a37e-4e73-a535-2d0d217362bc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:3vyb5uzx) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "850c741319d14012907a83d84dba3284",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.012 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.061720…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>levenshtein distance</td><td>█▅▅▅▅▃▁</td></tr><tr><td>train loss</td><td>█▄▃▃▃▂▁</td></tr><tr><td>validation loss</td><td>███▇▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>levenshtein distance</td><td>18.09255</td></tr><tr><td>train loss</td><td>2.6327</td></tr><tr><td>validation loss</td><td>2.55744</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">feasible-wave-6</strong>: <a href=\"https://wandb.ai/dl-studygroup/project/runs/3vyb5uzx\" target=\"_blank\">https://wandb.ai/dl-studygroup/project/runs/3vyb5uzx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20221204_142540-3vyb5uzx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:3vyb5uzx). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221204_142810-mc9c1k0n</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/dl-studygroup/project/runs/mc9c1k0n\" target=\"_blank\">playful-spaceship-7</a></strong> to <a href=\"https://wandb.ai/dl-studygroup/project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    reinit = True,\n",
        "    project = \"project\",\n",
        "    config = baseline_config\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7VX5D0yR-qb"
      },
      "outputs": [],
      "source": [
        "optimizer =  torch.optim.AdamW(model.parameters(), lr=baseline_config['lr'], weight_decay=1e-5) # What goes in here?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVnXr0EsEMRn"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.loss import CTCLoss\n",
        "\n",
        "criterion = CTCLoss()\n",
        "\n",
        "\n",
        "decoder = CTCBeamDecoder(\n",
        "    LABELS,\n",
        "    beam_width = config[\"beam_width\"],\n",
        "    num_processes = 4,\n",
        "    log_probs_input = True\n",
        ")\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = 2, factor = 0.5, min_lr = 2e-6, mode = \"min\")\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZY9mQpDVEHLm"
      },
      "outputs": [],
      "source": [
        "def calculate_levenshtein(h, y, lh, ly, decoder, labels):\n",
        "\n",
        "    beam_results, beam_scores, timesteps, out_lens = decoder.decode(h, seq_lens = lh)\n",
        "\n",
        "    batch_size = out_lens.shape[0]\n",
        "    distance = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      h_sliced = beam_results[i][0][:out_lens[i][0]]\n",
        "      y_sliced = y[i][:ly[i]]\n",
        "      h_string = \"\".join([labels[n] for n in h_sliced])\n",
        "      y_string = \"\".join([labels[n] for n in y_sliced])\n",
        "      distance += Levenshtein.distance(h_string, y_string)\n",
        "\n",
        "    distance /= batch_size\n",
        "\n",
        "    return distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kjx0MqkEQLK",
        "outputId": "ab20dd2e-7547-4fc1-b354-7e1a67e64979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output of model:  torch.Size([64, 44, 43])\n",
            "loss: 5.496857166290283\n",
            "lev-distance: 29.296875\n"
          ]
        }
      ],
      "source": [
        "# SANITY CHECK FOR BASELINE MODEL\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(train_loader):\n",
        "\n",
        "      mfccs, phonemes, len_mfccs, len_phonemes = data\n",
        "      mfccs, phonemes = mfccs.to(device), phonemes.to(device) \n",
        "\n",
        "      with torch.cuda.amp.autocast():\n",
        "        out, lens = model(mfccs, len_mfccs)\n",
        "\n",
        "      print(\"Output of model: \", out.shape)\n",
        "\n",
        "      loss = criterion(torch.log(out).permute(1,0,2), phonemes, lens, len_phonemes) # What goes in here?\n",
        "      print(f\"loss: {loss}\")\n",
        "\n",
        "      distance = calculate_levenshtein(torch.log(out), phonemes, lens, len_phonemes, decoder, LABELS, debug = False)\n",
        "      print(f\"lev-distance: {distance}\")\n",
        "\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykJJzXgSOPI-"
      },
      "source": [
        "## Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nqLiAmkMMBc"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "def evaluate(data_loader, model, epoch):\n",
        "    model.eval()\n",
        "    dist = 0\n",
        "    loss = 0\n",
        "    batch_bar = tqdm(total=len(data_loader), dynamic_ncols=True, leave=False, position=0, desc='Val') \n",
        "\n",
        "    phone_true_list = []\n",
        "    phone_pred_list = []\n",
        "\n",
        "    for i, data in enumerate(data_loader):\n",
        "\n",
        "        mfccs, phonemes, len_mfccs, len_phonemes = data\n",
        "        mfccs, phonemes = mfccs.to(device), phonemes.to(device) \n",
        "\n",
        "        with torch.inference_mode():\n",
        "          out, lens = model(mfccs, len_mfccs)\n",
        "    \n",
        "\n",
        "        loss = criterion(torch.log(out).permute(1,0,2), phonemes, lens, len_phonemes)\n",
        "\n",
        "        dist += calculate_levenshtein(torch.log(out), phonemes, lens, len_phonemes, decoder, LABELS, debug = False)\n",
        "\n",
        "        del mfccs, phonemes, out\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    dist /= len(data_loader)\n",
        "\n",
        "    return loss, dist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vH4QStLUjH8"
      },
      "outputs": [],
      "source": [
        "def train_step(train_loader, model, optimizer, criterion, scheduler, scaler):\n",
        "  \n",
        "    model.train()\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "    train_loss = 0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        mfccs, phonemes, len_mfccs, len_phonemes = data\n",
        "        mfccs, phonemes = mfccs.to(device), phonemes.to(device) \n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "          out, lens = model(mfccs, len_mfccs)\n",
        "\n",
        "        loss = criterion(torch.log(out).permute(1,0,2), phonemes, lens, len_phonemes)\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            loss = f\"{train_loss/ (i+1):.4f}\",\n",
        "            lr = f\"{optimizer.param_groups[0]['lr']}\"\n",
        "        )\n",
        "\n",
        "        train_loss += loss\n",
        "        batch_bar.update()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "    \n",
        "    batch_bar.close()\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    return train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxyZz9Du6YzP"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "best_val_dist = float('inf')\n",
        "\n",
        "name = \"baseline\"\n",
        "\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "for epoch in range(baseline_config['epochs']):\n",
        "    print(\"\\nEpoch {}/{}\".format(epoch+1, baseline_config['epochs']))\n",
        "    train_loss = train_step(train_loader, model, optimizer, criterion, scheduler, scaler)\n",
        "    print(\"\\tTrain Loss: {:.4f}\".format(train_loss))\n",
        "    \n",
        "    validation_loss, levenshtein_distance = evaluate(val_loader, model, epoch)\n",
        "    print(\"\\tLevenshtein Distance: {}\".format(levenshtein_distance))\n",
        "\n",
        "    validation_losses.append(validation_loss)\n",
        "\n",
        "    scheduler.step(levenshtein_distance)\n",
        "\n",
        "    if levenshtein_distance < best_val_dist:\n",
        "      path = \"/content/drive/MyDrive/checkpoint_{}.pth\".format(name) \n",
        "      print(\"Saving model\")\n",
        "      torch.save({'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'val_dist': levenshtein_distance, \n",
        "                  'epoch': epoch}, path)\n",
        "      \n",
        "      best_val_dist = levenshtein_distance\n",
        "      wandb.save('checkpoint.pth')\n",
        "    \n",
        "    wandb.log({\"train loss\": train_loss, \"levenshtein distance\": levenshtein_distance, \"validation loss\": validation_loss})\n",
        "\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiG7lT5j1TlU"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/{}.pth\".format(\"checkpoint_baseline_final\")\n",
        "checkpoint = torch.load(path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "best_val_dist = checkpoint['val_dist']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmzxvegt2M1m",
        "outputId": "ebb2dbae-1ab4-4539-c761-02df14028578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation Distance for Baseline Model:  6.688701923076923\n"
          ]
        }
      ],
      "source": [
        "print(\"Best Validation Distance for Baseline Model: \", best_val_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPEKQPvxIIEU"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/checkpoint_first.pth\"\n",
        "checkpoint = torch.load(path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "best_val_dist = checkpoint['val_dist']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZTpim0VIMl3",
        "outputId": "aab67888-e6f6-44e6-c96d-527a35e31e97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation Distance for Baseline Model:  7.1983173076923075\n"
          ]
        }
      ],
      "source": [
        "print(\"Best Validation Distance for Baseline Model: \", best_val_dist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_qqy_8OP5WL"
      },
      "source": [
        "# RL Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load baseline model"
      ],
      "metadata": {
        "id": "LxD1FG3jptXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"checkpoint_baseline_final.pth\")\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSmyuQiBpbZg",
        "outputId": "3d422dc3-b6ee-407d-ff17-6e4cb46a0eaa"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3qEh2E9QAJV"
      },
      "source": [
        "## Loss function, optimizer setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jHuuUYY7Q87K"
      },
      "outputs": [],
      "source": [
        "finetuning_config = {\n",
        "    \"lr\" : 1e-4,\n",
        "    \"epochs\" : 50,\n",
        "    \"scheduler\": \"ReduceLR\",\n",
        "    \"layers\": \"LSTM(128, 128) with dropout, Linear(256)\",\n",
        "    \"num_samples\": 5\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "V5xNYjHjRFfX",
        "outputId": "cfa3017d-483e-4142-a234-8e4543db72d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manushakamath\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221208_170558-1h8tn3zs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/anushakamath/11785-project/runs/1h8tn3zs\" target=\"_blank\">dandy-galaxy-12</a></strong> to <a href=\"https://wandb.ai/anushakamath/11785-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    reinit = True,\n",
        "    project = \"11785-project\",\n",
        "    config = finetuning_config\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "eoBmcXlAEnd2"
      },
      "outputs": [],
      "source": [
        "class MultinomialDecode:\n",
        "    def __init__(self, num_samples=1):\n",
        "        self.num_samples = num_samples\n",
        "    \n",
        "    def decode(self, logits, debug=False):\n",
        "      samples = torch.multinomial(logits, self.num_samples, replacement=True)\n",
        "      if debug:\n",
        "        print(logits[0], samples[0])\n",
        "      predicted = []\n",
        "      for i in range(self.num_samples):\n",
        "        pred = \"\"\n",
        "        prev = \"\"\n",
        "        for t in range(samples.shape[0]):\n",
        "          curr = mapping[PHONEMES[samples[t, i].item()]]\n",
        "\n",
        "          if t == 0:\n",
        "              pred += curr\n",
        "              prev = curr\n",
        "          else:\n",
        "              if curr != prev and curr != \" \":\n",
        "                  pred += curr\n",
        "                  prev = curr\n",
        "              if curr == \" \":\n",
        "                  prev = \"\"\n",
        "        predicted.append(pred)\n",
        "      samples =  torch.arange(logits.size(0)).to(device)[:, None] * logits.size(1) + samples.to(device)\n",
        "      # print(samples)\n",
        "      # print(logits)\n",
        "      # print(torch.take(logits, samples))\n",
        "      # print(torch.grad_fn)\n",
        "      return predicted, torch.take(logits, samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "hpTDVKusDEy9"
      },
      "outputs": [],
      "source": [
        "class RLLoss:\n",
        "    def __init__(self, decoder):\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def __call__(self, logits, target, input_lengths, target_lengths, return_dist=False, debug=False):\n",
        "      return self.forward(logits, target, input_lengths, target_lengths, return_dist, debug=debug)\n",
        "\n",
        "    def forward(self, logits, target, input_lengths, target_lengths, return_dist=False, debug=False):\n",
        "      batch_size, timesteps, _ = logits.shape\n",
        "\n",
        "      total_loss = 0.0\n",
        "\n",
        "      total_dist = 0.0\n",
        "\n",
        "      for i in range(batch_size):\n",
        "        probs = logits[i, :input_lengths[i], :]\n",
        "        predicted, probs = self.decoder.decode(probs)\n",
        "\n",
        "        actual = \"\".join([mapping[PHONEMES[j]] for j in target[i, :target_lengths[i]]])\n",
        "\n",
        "        sample_distances = []\n",
        "\n",
        "        for sample in range(len(predicted)):\n",
        "          sample_distances.append(Levenshtein.distance(predicted[sample], actual))\n",
        "          if i % 25 == 0 and debug:\n",
        "              print(\"Batch\", i+1, \"sample\", sample + 1, \"Levenshtein Distance:\", sample_distances[-1])\n",
        "          if sample == (len(predicted)-1) and debug:\n",
        "            print()\n",
        "        \n",
        "        total_dist += sum(sample_distances) / len(predicted)\n",
        "        sample_distances = torch.tensor(sample_distances, dtype=torch.float, requires_grad=True).to(device)\n",
        "        sample_distances = sample_distances - torch.mean(sample_distances)\n",
        "        total_loss += torch.sum(sample_distances * torch.sum(torch.log(probs), axis=0)) / len(predicted)\n",
        "\n",
        "      total_loss = total_loss / batch_size\n",
        "      total_dist = total_dist / batch_size\n",
        "      if return_dist:\n",
        "        return total_loss, total_dist\n",
        "\n",
        "      return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "iGoozH2nd6KB"
      },
      "outputs": [],
      "source": [
        "decoder = MultinomialDecode(finetuning_config[\"num_samples\"])\n",
        "\n",
        "criterion = RLLoss(decoder)\n",
        "\n",
        "optimizer =  torch.optim.AdamW(model.parameters(), lr=finetuning_config['lr'], weight_decay=1e-4) # What goes in here?\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = 5, factor = 0.2, min_lr = 1e-7, mode = \"min\", verbose=True)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnTLL-5gMBrY",
        "outputId": "40da865f-866f-4654-eb32-93ea1839464d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 176, 26])\n",
            "torch.Size([64, 23])\n",
            "Output of model:  torch.Size([64, 176, 43])\n",
            "Batch 1 sample 1 Levenshtein Distance: 6\n",
            "Batch 1 sample 2 Levenshtein Distance: 8\n",
            "Batch 1 sample 3 Levenshtein Distance: 7\n",
            "Batch 1 sample 4 Levenshtein Distance: 5\n",
            "Batch 1 sample 5 Levenshtein Distance: 8\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 8\n",
            "Batch 26 sample 2 Levenshtein Distance: 6\n",
            "Batch 26 sample 3 Levenshtein Distance: 6\n",
            "Batch 26 sample 4 Levenshtein Distance: 8\n",
            "Batch 26 sample 5 Levenshtein Distance: 6\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 6\n",
            "Batch 51 sample 2 Levenshtein Distance: 12\n",
            "Batch 51 sample 3 Levenshtein Distance: 5\n",
            "Batch 51 sample 4 Levenshtein Distance: 6\n",
            "Batch 51 sample 5 Levenshtein Distance: 6\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "loss: -3.201996326446533\n",
            "lev dist: 9.062499999999998\n"
          ]
        }
      ],
      "source": [
        "# SANITY CHECK FOR FINE-TUNING\n",
        "model = model.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(train_loader):\n",
        "      \n",
        "      mfccs, phonemes, len_mfccs, len_phonemes = data\n",
        "      mfccs, phonemes = mfccs.to(device), phonemes.to(device) \n",
        "      print(mfccs.shape)\n",
        "      print(phonemes.shape)\n",
        "\n",
        "      with torch.cuda.amp.autocast():\n",
        "        out, lens = model(mfccs, len_mfccs)\n",
        "\n",
        "      print(\"Output of model: \", out.shape)\n",
        "\n",
        "      loss, dist = criterion(out, phonemes, lens, len_phonemes, return_dist=True, debug=True)\n",
        "      print(f\"loss: {loss}\")\n",
        "      print(f\"lev dist: {dist}\")\n",
        "\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fLLj5KIMMOe"
      },
      "source": [
        "## Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "JRvfQBPYcG5A"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "def evaluate(data_loader, model, epoch, decoder):\n",
        "    model.eval()\n",
        "    dist = 0\n",
        "    loss = 0\n",
        "    batch_bar = tqdm(total=len(data_loader), dynamic_ncols=True, leave=False, position=0, desc='Val') \n",
        "\n",
        "    phone_true_list = []\n",
        "    phone_pred_list = []\n",
        "\n",
        "    for i, data in enumerate(data_loader):\n",
        "\n",
        "        mfccs, phonemes, len_mfccs, len_phonemes = data\n",
        "        mfccs, phonemes = mfccs.to(device), phonemes.to(device) \n",
        "\n",
        "        with torch.inference_mode():\n",
        "          out, lens = model(mfccs, len_mfccs)\n",
        "\n",
        "        if i % 25 == 0:\n",
        "          debug = True\n",
        "        else:\n",
        "          debug = False\n",
        "        loss, lev_dist = criterion(out, phonemes, lens, len_phonemes, True, debug=debug)\n",
        "\n",
        "        dist += lev_dist\n",
        "        del mfccs, phonemes, out\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    dist /= len(data_loader)\n",
        "\n",
        "    return loss, dist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Lp9vHsnfQjit"
      },
      "outputs": [],
      "source": [
        "def train_step(train_loader, model, optimizer, criterion, scheduler, scaler):\n",
        "  \n",
        "    model.train()\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "    train_loss = 0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        mfccs, phonemes, len_mfccs, len_phonemes = data\n",
        "        mfccs, phonemes = mfccs.to(device), phonemes.to(device) \n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "          out, lens = model(mfccs, len_mfccs)\n",
        "\n",
        "        loss = criterion(out, phonemes, lens, len_phonemes)\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            loss = f\"{train_loss/ (i+1):.4f}\",\n",
        "            lr = f\"{optimizer.param_groups[0]['lr']}\"\n",
        "        )\n",
        "\n",
        "        train_loss += loss\n",
        "        batch_bar.update()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "    \n",
        "    batch_bar.close()\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    return train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5t9wXTxIhEw",
        "outputId": "d6b15be2-024b-492e-c059-86178f981909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -1.5686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 9\n",
            "Batch 1 sample 2 Levenshtein Distance: 10\n",
            "Batch 1 sample 3 Levenshtein Distance: 10\n",
            "Batch 1 sample 4 Levenshtein Distance: 8\n",
            "Batch 1 sample 5 Levenshtein Distance: 9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 9\n",
            "Batch 26 sample 2 Levenshtein Distance: 12\n",
            "Batch 26 sample 3 Levenshtein Distance: 12\n",
            "Batch 26 sample 4 Levenshtein Distance: 7\n",
            "Batch 26 sample 5 Levenshtein Distance: 10\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 5\n",
            "Batch 51 sample 2 Levenshtein Distance: 7\n",
            "Batch 51 sample 3 Levenshtein Distance: 4\n",
            "Batch 51 sample 4 Levenshtein Distance: 4\n",
            "Batch 51 sample 5 Levenshtein Distance: 6\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.609134615384614\n",
            "\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -1.1531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 10\n",
            "Batch 1 sample 2 Levenshtein Distance: 9\n",
            "Batch 1 sample 3 Levenshtein Distance: 9\n",
            "Batch 1 sample 4 Levenshtein Distance: 9\n",
            "Batch 1 sample 5 Levenshtein Distance: 11\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 8\n",
            "Batch 26 sample 2 Levenshtein Distance: 9\n",
            "Batch 26 sample 3 Levenshtein Distance: 10\n",
            "Batch 26 sample 4 Levenshtein Distance: 10\n",
            "Batch 26 sample 5 Levenshtein Distance: 8\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 6\n",
            "Batch 51 sample 2 Levenshtein Distance: 5\n",
            "Batch 51 sample 3 Levenshtein Distance: 5\n",
            "Batch 51 sample 4 Levenshtein Distance: 8\n",
            "Batch 51 sample 5 Levenshtein Distance: 7\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.5718749999999995\n",
            "\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.9888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 8\n",
            "Batch 1 sample 2 Levenshtein Distance: 9\n",
            "Batch 1 sample 3 Levenshtein Distance: 10\n",
            "Batch 1 sample 4 Levenshtein Distance: 10\n",
            "Batch 1 sample 5 Levenshtein Distance: 10\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 11\n",
            "Batch 26 sample 2 Levenshtein Distance: 9\n",
            "Batch 26 sample 3 Levenshtein Distance: 9\n",
            "Batch 26 sample 4 Levenshtein Distance: 11\n",
            "Batch 26 sample 5 Levenshtein Distance: 11\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 5\n",
            "Batch 51 sample 2 Levenshtein Distance: 7\n",
            "Batch 51 sample 3 Levenshtein Distance: 6\n",
            "Batch 51 sample 4 Levenshtein Distance: 8\n",
            "Batch 51 sample 5 Levenshtein Distance: 5\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.473798076923075\n",
            "\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.9225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 9\n",
            "Batch 1 sample 2 Levenshtein Distance: 11\n",
            "Batch 1 sample 3 Levenshtein Distance: 9\n",
            "Batch 1 sample 4 Levenshtein Distance: 11\n",
            "Batch 1 sample 5 Levenshtein Distance: 9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 10\n",
            "Batch 26 sample 2 Levenshtein Distance: 11\n",
            "Batch 26 sample 3 Levenshtein Distance: 11\n",
            "Batch 26 sample 4 Levenshtein Distance: 12\n",
            "Batch 26 sample 5 Levenshtein Distance: 10\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 7\n",
            "Batch 51 sample 2 Levenshtein Distance: 8\n",
            "Batch 51 sample 3 Levenshtein Distance: 6\n",
            "Batch 51 sample 4 Levenshtein Distance: 7\n",
            "Batch 51 sample 5 Levenshtein Distance: 6\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.402163461538462\n",
            "\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.8421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 8\n",
            "Batch 1 sample 2 Levenshtein Distance: 11\n",
            "Batch 1 sample 3 Levenshtein Distance: 10\n",
            "Batch 1 sample 4 Levenshtein Distance: 9\n",
            "Batch 1 sample 5 Levenshtein Distance: 10\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 12\n",
            "Batch 26 sample 2 Levenshtein Distance: 9\n",
            "Batch 26 sample 3 Levenshtein Distance: 11\n",
            "Batch 26 sample 4 Levenshtein Distance: 12\n",
            "Batch 26 sample 5 Levenshtein Distance: 10\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 6\n",
            "Batch 51 sample 2 Levenshtein Distance: 7\n",
            "Batch 51 sample 3 Levenshtein Distance: 7\n",
            "Batch 51 sample 4 Levenshtein Distance: 6\n",
            "Batch 51 sample 5 Levenshtein Distance: 6\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.418990384615384\n",
            "\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.8186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 9\n",
            "Batch 1 sample 2 Levenshtein Distance: 10\n",
            "Batch 1 sample 3 Levenshtein Distance: 8\n",
            "Batch 1 sample 4 Levenshtein Distance: 9\n",
            "Batch 1 sample 5 Levenshtein Distance: 9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 8\n",
            "Batch 26 sample 2 Levenshtein Distance: 10\n",
            "Batch 26 sample 3 Levenshtein Distance: 8\n",
            "Batch 26 sample 4 Levenshtein Distance: 7\n",
            "Batch 26 sample 5 Levenshtein Distance: 6\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 8\n",
            "Batch 51 sample 2 Levenshtein Distance: 6\n",
            "Batch 51 sample 3 Levenshtein Distance: 5\n",
            "Batch 51 sample 4 Levenshtein Distance: 6\n",
            "Batch 51 sample 5 Levenshtein Distance: 4\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.38125\n",
            "\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.7833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 11\n",
            "Batch 1 sample 2 Levenshtein Distance: 9\n",
            "Batch 1 sample 3 Levenshtein Distance: 12\n",
            "Batch 1 sample 4 Levenshtein Distance: 10\n",
            "Batch 1 sample 5 Levenshtein Distance: 10\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 8\n",
            "Batch 26 sample 2 Levenshtein Distance: 8\n",
            "Batch 26 sample 3 Levenshtein Distance: 6\n",
            "Batch 26 sample 4 Levenshtein Distance: 9\n",
            "Batch 26 sample 5 Levenshtein Distance: 7\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 6\n",
            "Batch 51 sample 2 Levenshtein Distance: 6\n",
            "Batch 51 sample 3 Levenshtein Distance: 7\n",
            "Batch 51 sample 4 Levenshtein Distance: 6\n",
            "Batch 51 sample 5 Levenshtein Distance: 5\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.301442307692308\n",
            "\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.7581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 10\n",
            "Batch 1 sample 2 Levenshtein Distance: 9\n",
            "Batch 1 sample 3 Levenshtein Distance: 10\n",
            "Batch 1 sample 4 Levenshtein Distance: 11\n",
            "Batch 1 sample 5 Levenshtein Distance: 10\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 9\n",
            "Batch 26 sample 2 Levenshtein Distance: 7\n",
            "Batch 26 sample 3 Levenshtein Distance: 9\n",
            "Batch 26 sample 4 Levenshtein Distance: 9\n",
            "Batch 26 sample 5 Levenshtein Distance: 9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 5\n",
            "Batch 51 sample 2 Levenshtein Distance: 8\n",
            "Batch 51 sample 3 Levenshtein Distance: 6\n",
            "Batch 51 sample 4 Levenshtein Distance: 8\n",
            "Batch 51 sample 5 Levenshtein Distance: 6\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.242307692307691\n",
            "\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.7445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 10\n",
            "Batch 1 sample 2 Levenshtein Distance: 10\n",
            "Batch 1 sample 3 Levenshtein Distance: 12\n",
            "Batch 1 sample 4 Levenshtein Distance: 11\n",
            "Batch 1 sample 5 Levenshtein Distance: 12\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 7\n",
            "Batch 26 sample 2 Levenshtein Distance: 8\n",
            "Batch 26 sample 3 Levenshtein Distance: 7\n",
            "Batch 26 sample 4 Levenshtein Distance: 7\n",
            "Batch 26 sample 5 Levenshtein Distance: 7\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 7\n",
            "Batch 51 sample 2 Levenshtein Distance: 7\n",
            "Batch 51 sample 3 Levenshtein Distance: 6\n",
            "Batch 51 sample 4 Levenshtein Distance: 7\n",
            "Batch 51 sample 5 Levenshtein Distance: 6\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.193509615384615\n",
            "\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.6926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 11\n",
            "Batch 1 sample 2 Levenshtein Distance: 11\n",
            "Batch 1 sample 3 Levenshtein Distance: 11\n",
            "Batch 1 sample 4 Levenshtein Distance: 9\n",
            "Batch 1 sample 5 Levenshtein Distance: 10\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 8\n",
            "Batch 26 sample 2 Levenshtein Distance: 7\n",
            "Batch 26 sample 3 Levenshtein Distance: 7\n",
            "Batch 26 sample 4 Levenshtein Distance: 8\n",
            "Batch 26 sample 5 Levenshtein Distance: 7\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 5\n",
            "Batch 51 sample 2 Levenshtein Distance: 6\n",
            "Batch 51 sample 3 Levenshtein Distance: 5\n",
            "Batch 51 sample 4 Levenshtein Distance: 8\n",
            "Batch 51 sample 5 Levenshtein Distance: 8\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.192307692307692\n",
            "\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.6900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 9\n",
            "Batch 1 sample 2 Levenshtein Distance: 10\n",
            "Batch 1 sample 3 Levenshtein Distance: 8\n",
            "Batch 1 sample 4 Levenshtein Distance: 8\n",
            "Batch 1 sample 5 Levenshtein Distance: 9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 6\n",
            "Batch 26 sample 2 Levenshtein Distance: 7\n",
            "Batch 26 sample 3 Levenshtein Distance: 8\n",
            "Batch 26 sample 4 Levenshtein Distance: 5\n",
            "Batch 26 sample 5 Levenshtein Distance: 8\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 5\n",
            "Batch 51 sample 2 Levenshtein Distance: 7\n",
            "Batch 51 sample 3 Levenshtein Distance: 5\n",
            "Batch 51 sample 4 Levenshtein Distance: 4\n",
            "Batch 51 sample 5 Levenshtein Distance: 8\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.207451923076923\n",
            "\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.6520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 10\n",
            "Batch 1 sample 2 Levenshtein Distance: 10\n",
            "Batch 1 sample 3 Levenshtein Distance: 10\n",
            "Batch 1 sample 4 Levenshtein Distance: 9\n",
            "Batch 1 sample 5 Levenshtein Distance: 9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 6\n",
            "Batch 26 sample 2 Levenshtein Distance: 6\n",
            "Batch 26 sample 3 Levenshtein Distance: 5\n",
            "Batch 26 sample 4 Levenshtein Distance: 7\n",
            "Batch 26 sample 5 Levenshtein Distance: 8\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 7\n",
            "Batch 51 sample 2 Levenshtein Distance: 5\n",
            "Batch 51 sample 3 Levenshtein Distance: 6\n",
            "Batch 51 sample 4 Levenshtein Distance: 6\n",
            "Batch 51 sample 5 Levenshtein Distance: 5\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.17764423076923\n",
            "\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.6258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 8\n",
            "Batch 1 sample 2 Levenshtein Distance: 9\n",
            "Batch 1 sample 3 Levenshtein Distance: 9\n",
            "Batch 1 sample 4 Levenshtein Distance: 10\n",
            "Batch 1 sample 5 Levenshtein Distance: 11\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 6\n",
            "Batch 26 sample 2 Levenshtein Distance: 7\n",
            "Batch 26 sample 3 Levenshtein Distance: 6\n",
            "Batch 26 sample 4 Levenshtein Distance: 8\n",
            "Batch 26 sample 5 Levenshtein Distance: 7\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 5\n",
            "Batch 51 sample 2 Levenshtein Distance: 4\n",
            "Batch 51 sample 3 Levenshtein Distance: 7\n",
            "Batch 51 sample 4 Levenshtein Distance: 4\n",
            "Batch 51 sample 5 Levenshtein Distance: 4\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.153365384615385\n",
            "\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.6341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 9\n",
            "Batch 1 sample 2 Levenshtein Distance: 9\n",
            "Batch 1 sample 3 Levenshtein Distance: 7\n",
            "Batch 1 sample 4 Levenshtein Distance: 9\n",
            "Batch 1 sample 5 Levenshtein Distance: 9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 9\n",
            "Batch 26 sample 2 Levenshtein Distance: 8\n",
            "Batch 26 sample 3 Levenshtein Distance: 9\n",
            "Batch 26 sample 4 Levenshtein Distance: 8\n",
            "Batch 26 sample 5 Levenshtein Distance: 4\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 6\n",
            "Batch 51 sample 2 Levenshtein Distance: 8\n",
            "Batch 51 sample 3 Levenshtein Distance: 6\n",
            "Batch 51 sample 4 Levenshtein Distance: 7\n",
            "Batch 51 sample 5 Levenshtein Distance: 9\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.078125\n",
            "\n",
            "Epoch 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.6032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 8\n",
            "Batch 1 sample 2 Levenshtein Distance: 8\n",
            "Batch 1 sample 3 Levenshtein Distance: 8\n",
            "Batch 1 sample 4 Levenshtein Distance: 8\n",
            "Batch 1 sample 5 Levenshtein Distance: 6\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 8\n",
            "Batch 26 sample 2 Levenshtein Distance: 10\n",
            "Batch 26 sample 3 Levenshtein Distance: 10\n",
            "Batch 26 sample 4 Levenshtein Distance: 8\n",
            "Batch 26 sample 5 Levenshtein Distance: 8\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 7\n",
            "Batch 51 sample 2 Levenshtein Distance: 7\n",
            "Batch 51 sample 3 Levenshtein Distance: 7\n",
            "Batch 51 sample 4 Levenshtein Distance: 4\n",
            "Batch 51 sample 5 Levenshtein Distance: 7\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.125961538461538\n",
            "\n",
            "Epoch 16/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.6366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 8\n",
            "Batch 1 sample 2 Levenshtein Distance: 9\n",
            "Batch 1 sample 3 Levenshtein Distance: 9\n",
            "Batch 1 sample 4 Levenshtein Distance: 7\n",
            "Batch 1 sample 5 Levenshtein Distance: 8\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 7\n",
            "Batch 26 sample 2 Levenshtein Distance: 7\n",
            "Batch 26 sample 3 Levenshtein Distance: 7\n",
            "Batch 26 sample 4 Levenshtein Distance: 6\n",
            "Batch 26 sample 5 Levenshtein Distance: 6\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 5\n",
            "Batch 51 sample 2 Levenshtein Distance: 7\n",
            "Batch 51 sample 3 Levenshtein Distance: 5\n",
            "Batch 51 sample 4 Levenshtein Distance: 7\n",
            "Batch 51 sample 5 Levenshtein Distance: 5\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.033894230769233\n",
            "\n",
            "Epoch 17/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.6026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 8\n",
            "Batch 1 sample 2 Levenshtein Distance: 9\n",
            "Batch 1 sample 3 Levenshtein Distance: 7\n",
            "Batch 1 sample 4 Levenshtein Distance: 8\n",
            "Batch 1 sample 5 Levenshtein Distance: 8\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 6\n",
            "Batch 26 sample 2 Levenshtein Distance: 10\n",
            "Batch 26 sample 3 Levenshtein Distance: 8\n",
            "Batch 26 sample 4 Levenshtein Distance: 8\n",
            "Batch 26 sample 5 Levenshtein Distance: 6\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 6\n",
            "Batch 51 sample 2 Levenshtein Distance: 6\n",
            "Batch 51 sample 3 Levenshtein Distance: 5\n",
            "Batch 51 sample 4 Levenshtein Distance: 5\n",
            "Batch 51 sample 5 Levenshtein Distance: 7\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 6.995673076923077\n",
            "\n",
            "Epoch 18/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: -0.5951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 sample 1 Levenshtein Distance: 8\n",
            "Batch 1 sample 2 Levenshtein Distance: 9\n",
            "Batch 1 sample 3 Levenshtein Distance: 7\n",
            "Batch 1 sample 4 Levenshtein Distance: 7\n",
            "Batch 1 sample 5 Levenshtein Distance: 8\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 26 sample 1 Levenshtein Distance: 11\n",
            "Batch 26 sample 2 Levenshtein Distance: 7\n",
            "Batch 26 sample 3 Levenshtein Distance: 7\n",
            "Batch 26 sample 4 Levenshtein Distance: 9\n",
            "Batch 26 sample 5 Levenshtein Distance: 8\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Batch 51 sample 1 Levenshtein Distance: 5\n",
            "Batch 51 sample 2 Levenshtein Distance: 5\n",
            "Batch 51 sample 3 Levenshtein Distance: 5\n",
            "Batch 51 sample 4 Levenshtein Distance: 7\n",
            "Batch 51 sample 5 Levenshtein Distance: 7\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLevenshtein Distance: 7.087259615384614\n",
            "\n",
            "Epoch 19/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  10%|▉         | 12/125 [00:13<02:11,  1.16s/it, loss=-0.5068, lr=0.0001]"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "best_val_dist = -float(\"inf\")\n",
        "\n",
        "name = \"finetuning_second\"\n",
        "\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "for epoch in range(finetuning_config['epochs']):\n",
        "    print(\"\\nEpoch {}/{}\".format(epoch+1, finetuning_config['epochs']))\n",
        "    train_loss = train_step(train_loader, model, optimizer, criterion, scheduler, scaler)\n",
        "    print(\"\\tTrain Loss: {:.4f}\".format(train_loss))\n",
        "    \n",
        "    validation_loss, levenshtein_distance = evaluate(val_loader, model, epoch, decoder)\n",
        "    print(\"\\tLevenshtein Distance: {}\".format(levenshtein_distance))\n",
        "\n",
        "    validation_losses.append(validation_loss)\n",
        "\n",
        "    scheduler.step(levenshtein_distance)\n",
        "\n",
        "    if levenshtein_distance < best_val_dist:\n",
        "      path = \"/content/drive/MyDrive/checkpoint_{}.pth\".format(name) \n",
        "      print(\"Saving model\")\n",
        "      torch.save({'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'val_dist': levenshtein_distance, \n",
        "                  'epoch': epoch}, path)\n",
        "      \n",
        "      best_val_dist = levenshtein_distance\n",
        "      wandb.save('checkpoint.pth')\n",
        "    \n",
        "    wandb.log({\"train loss\": train_loss, \"levenshtein distance\": levenshtein_distance, \"validation loss\": validation_loss})\n",
        "\n",
        "run.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-4THJ6SVRQTS",
        "outputId": "699787e0-a591-473d-f5a7-03622d091938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -1.0754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.778846153846154\n",
            "Saving model\n",
            "\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.8039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.737980769230769\n",
            "Saving model\n",
            "\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.7610\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.65625\n",
            "Saving model\n",
            "\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.6550\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.666466346153846\n",
            "\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.6057\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.6532451923076925\n",
            "Saving model\n",
            "\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.6484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.6436298076923075\n",
            "Saving model\n",
            "\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.5279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.500600961538462\n",
            "Saving model\n",
            "\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.5596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.546875\n",
            "\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.5199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.493389423076923\n",
            "Saving model\n",
            "\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.5433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.678485576923077\n",
            "\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.5303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.5342548076923075\n",
            "\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.5177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.5703125\n",
            "\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.4382\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.460336538461538\n",
            "Saving model\n",
            "\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.5166\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.4483173076923075\n",
            "Saving model\n",
            "\n",
            "Epoch 15/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.5045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.512019230769231\n",
            "\n",
            "Epoch 16/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.4635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.435697115384615\n",
            "Saving model\n",
            "\n",
            "Epoch 17/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.4217\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.424278846153846\n",
            "Saving model\n",
            "\n",
            "Epoch 18/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.4490\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.408653846153846\n",
            "Saving model\n",
            "\n",
            "Epoch 19/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.4265\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.403846153846154\n",
            "Saving model\n",
            "\n",
            "Epoch 20/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.4311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.383413461538462\n",
            "Saving model\n",
            "\n",
            "Epoch 21/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.4423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.4188701923076925\n",
            "\n",
            "Epoch 22/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.4501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.3515625\n",
            "Saving model\n",
            "\n",
            "Epoch 23/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.4033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.396033653846154\n",
            "\n",
            "Epoch 24/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3925\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.289663461538462\n",
            "Saving model\n",
            "\n",
            "Epoch 25/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.425480769230769\n",
            "\n",
            "Epoch 26/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3776\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.338341346153846\n",
            "\n",
            "Epoch 27/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.4202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.3203125\n",
            "\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.265625\n",
            "Saving model\n",
            "\n",
            "Epoch 29/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3893\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.265024038461538\n",
            "Saving model\n",
            "\n",
            "Epoch 30/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.3046875\n",
            "\n",
            "Epoch 31/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.365384615384615\n",
            "\n",
            "Epoch 32/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.4006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.338341346153846\n",
            "\n",
            "Epoch 33/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.402644230769231\n",
            "\n",
            "Epoch 34/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.376802884615385\n",
            "Epoch 00034: reducing learning rate of group 0 to 2.0000e-05.\n",
            "\n",
            "Epoch 35/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.325721153846154\n",
            "\n",
            "Epoch 36/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.3016826923076925\n",
            "\n",
            "Epoch 37/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3610\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.2920673076923075\n",
            "\n",
            "Epoch 38/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.263822115384615\n",
            "Saving model\n",
            "\n",
            "Epoch 39/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.227764423076923\n",
            "Saving model\n",
            "\n",
            "Epoch 40/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.2548076923076925\n",
            "\n",
            "Epoch 41/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.242788461538462\n",
            "\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3351\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.208533653846154\n",
            "Saving model\n",
            "\n",
            "Epoch 43/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.4174\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.230168269230769\n",
            "\n",
            "Epoch 44/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.2931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.2235576923076925\n",
            "\n",
            "Epoch 45/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.275240384615385\n",
            "\n",
            "Epoch 46/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.217548076923077\n",
            "\n",
            "Epoch 47/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.209134615384615\n",
            "\n",
            "Epoch 48/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.198918269230769\n",
            "Saving model\n",
            "\n",
            "Epoch 49/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.201923076923077\n",
            "\n",
            "Epoch 50/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: -0.3714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                           "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLevenshtein Distance: 7.1983173076923075\n",
            "Saving model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>levenshtein distance</td><td>██▇▇▆▅▅▅▅▅▄▄▄▄▄▃▄▃▃▂▃▂▂▂▃▃▃▃▂▂▂▁▂▁▁▁▁▁▁▁</td></tr><tr><td>train loss</td><td>▁▃▄▅▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████▇</td></tr><tr><td>validation loss</td><td>▁▃▅▅▄▆▇▅▇▇▆▇▆▇▆▄▆▆▇▅█▆▆▇▇▇▇█▅▆▆▆▇▇▅▅▆▅▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>levenshtein distance</td><td>7.19832</td></tr><tr><td>train loss</td><td>-0.37139</td></tr><tr><td>validation loss</td><td>-0.24819</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">comfy-dragon-7</strong>: <a href=\"https://wandb.ai/dl-studygroup/11785-project/runs/btx5bpvo\" target=\"_blank\">https://wandb.ai/dl-studygroup/11785-project/runs/btx5bpvo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20221206_004009-btx5bpvo/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "best_val_dist = best_val_dist\n",
        "\n",
        "name = \"finetuning_second\"\n",
        "\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "for epoch in range(finetuning_config['epochs']):\n",
        "    print(\"\\nEpoch {}/{}\".format(epoch+1, finetuning_config['epochs']))\n",
        "    train_loss = train_step(train_loader, model, optimizer, criterion, scheduler, scaler)\n",
        "    print(\"\\tTrain Loss: {:.4f}\".format(train_loss))\n",
        "    \n",
        "    validation_loss, levenshtein_distance = evaluate(val_loader, model, epoch, decoder)\n",
        "    print(\"\\tLevenshtein Distance: {}\".format(levenshtein_distance))\n",
        "\n",
        "    validation_losses.append(validation_loss)\n",
        "\n",
        "    scheduler.step(levenshtein_distance)\n",
        "\n",
        "    if levenshtein_distance < best_val_dist:\n",
        "      path = \"/content/drive/MyDrive/checkpoint_{}.pth\".format(name) \n",
        "      print(\"Saving model\")\n",
        "      torch.save({'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'val_dist': levenshtein_distance, \n",
        "                  'epoch': epoch}, path)\n",
        "      \n",
        "      best_val_dist = levenshtein_distance\n",
        "      wandb.save('checkpoint.pth')\n",
        "    \n",
        "    wandb.log({\"train loss\": train_loss, \"levenshtein distance\": levenshtein_distance, \"validation loss\": validation_loss})\n",
        "\n",
        "run.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVS6bITTApE2"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/checkpoint_first.pth\"\n",
        "torch.save({'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_dist': levenshtein_distance, \n",
        "            'epoch': epoch}, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvrcVPIUHzsp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "m8uvhx-wo1Wi",
        "FOqWt8BWo_xn",
        "IBwunYpyugFg",
        "AVyEMAZBOF5i",
        "ykJJzXgSOPI-"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}